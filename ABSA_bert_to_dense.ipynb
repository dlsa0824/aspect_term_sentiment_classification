{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把input根據aspect term拆成左右兩邊丟掉bert，去預測polarity ---> 失敗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對處理好的laptop、restaurant的train、test資料作前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把dataframe裡的text切成text左邊跟右邊的function\n",
    "def split_text(df):\n",
    "    df['left_text'] = 'N/A'\n",
    "    df['right_text'] = 'N/A'\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        text = df.loc[i, 'text']\n",
    "        aspect = df.loc[i, 'aspect']\n",
    "        text_split = text.split(aspect) # 根據aspect切割text左右邊\n",
    "        \n",
    "        df.loc[i,'left_text'] = text_split[0]+aspect\n",
    "        df.loc[i,'right_text'] = aspect+text_split[1]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5915/5915 [00:01<00:00, 3894.72it/s]\n",
      "100%|██████████| 638/638 [00:00<00:00, 3991.59it/s]\n",
      "100%|██████████| 1120/1120 [00:00<00:00, 3986.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>positive</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech support would not fix the problem unless ...</td>\n",
       "      <td>tech support</td>\n",
       "      <td>negative</td>\n",
       "      <td>tech support</td>\n",
       "      <td>tech support would not fix the problem unless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set up was easy.</td>\n",
       "      <td>Set up</td>\n",
       "      <td>positive</td>\n",
       "      <td>Set up</td>\n",
       "      <td>Set up was easy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>Windows 8</td>\n",
       "      <td>negative</td>\n",
       "      <td>Did not enjoy the new Windows 8</td>\n",
       "      <td>Windows 8 and touchscreen functions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>touchscreen functions</td>\n",
       "      <td>negative</td>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>touchscreen functions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>internal speakers</td>\n",
       "      <td>negative</td>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>internal speakers, it's hard for me to find th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>price tag</td>\n",
       "      <td>positive</td>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>price tag.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>click pads</td>\n",
       "      <td>negative</td>\n",
       "      <td>Other than not being a fan of click pads</td>\n",
       "      <td>click pads (industry standard these days) and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No installation disk (DVD) is included.</td>\n",
       "      <td>installation disk (DVD)</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No installation disk (DVD)</td>\n",
       "      <td>installation disk (DVD) is included.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's fast, light, and simple to use.</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>It's fast, light, and simple to use</td>\n",
       "      <td>use.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   aspect  \\\n",
       "0  Boot time is super fast, around anywhere from ...                Boot time   \n",
       "1  tech support would not fix the problem unless ...             tech support   \n",
       "2                                   Set up was easy.                   Set up   \n",
       "3  Did not enjoy the new Windows 8 and touchscree...                Windows 8   \n",
       "4  Did not enjoy the new Windows 8 and touchscree...    touchscreen functions   \n",
       "5  Other than not being a fan of click pads (indu...        internal speakers   \n",
       "6  Other than not being a fan of click pads (indu...                price tag   \n",
       "7  Other than not being a fan of click pads (indu...               click pads   \n",
       "8            No installation disk (DVD) is included.  installation disk (DVD)   \n",
       "9               It's fast, light, and simple to use.                      use   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0  positive                                          Boot time   \n",
       "1  negative                                       tech support   \n",
       "2  positive                                             Set up   \n",
       "3  negative                    Did not enjoy the new Windows 8   \n",
       "4  negative  Did not enjoy the new Windows 8 and touchscree...   \n",
       "5  negative  Other than not being a fan of click pads (indu...   \n",
       "6  positive  Other than not being a fan of click pads (indu...   \n",
       "7  negative           Other than not being a fan of click pads   \n",
       "8   neutral                         No installation disk (DVD)   \n",
       "9  positive                It's fast, light, and simple to use   \n",
       "\n",
       "                                          right_text  \n",
       "0  Boot time is super fast, around anywhere from ...  \n",
       "1  tech support would not fix the problem unless ...  \n",
       "2                                   Set up was easy.  \n",
       "3               Windows 8 and touchscreen functions.  \n",
       "4                             touchscreen functions.  \n",
       "5  internal speakers, it's hard for me to find th...  \n",
       "6                                         price tag.  \n",
       "7  click pads (industry standard these days) and ...  \n",
       "8               installation disk (DVD) is included.  \n",
       "9                                               use.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_train = pd.read_csv('dataset/laptop_train_processed.csv', encoding='utf-8')\n",
    "restaurant_train = pd.read_csv('dataset/restaurant_train_processed.csv', encoding='utf-8')\n",
    "laptop_test = pd.read_csv('dataset/laptop_test_processed.csv', encoding='utf-8')\n",
    "restaurant_test = pd.read_csv('dataset/restaurant_test_processed.csv', encoding='utf-8')\n",
    "\n",
    "# 把train的資料串在一起且切割text\n",
    "train_data = laptop_train.append(restaurant_train)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "train_data = split_text(train_data)\n",
    "\n",
    "# laptop_test切割text\n",
    "laptop_test = split_text(laptop_test)\n",
    "\n",
    "#restaurant_test切割text\n",
    "restaurant_test = split_text(restaurant_test)\n",
    "\n",
    "#把test的資料串在一起且切割text\n",
    "# test_data = laptop_test.append(restaurant_test)\n",
    "# test_data = test_data.reset_index(drop=True)\n",
    "# test_data = split_text(test_data)\n",
    "\n",
    "laptop_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I charge it at night and skip taking the cord\n",
      "cord with me because of the good battery life.\n"
     ]
    }
   ],
   "source": [
    "# print一個出來看看\n",
    "print(train_data.loc[0,'left_text'])\n",
    "print(train_data.loc[0,'right_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pos neg neutral\n",
      "train 3151 1671 1093\n",
      "laptop 341 128 169\n",
      "restau 728 196 196\n"
     ]
    }
   ],
   "source": [
    "#看train跟test的資料每一個label各是多少個\n",
    "train_data_positive = train_data[train_data['polarity'] == 'positive']\n",
    "train_data_negative = train_data[train_data['polarity'] == 'negative']\n",
    "train_data_neutral = train_data[train_data['polarity'] == 'neutral']\n",
    "\n",
    "laptop_test_positive = laptop_test[laptop_test['polarity'] == 'positive']\n",
    "laptop_test_negative = laptop_test[laptop_test['polarity'] == 'negative']\n",
    "laptop_test_neutral = laptop_test[laptop_test['polarity'] == 'neutral']\n",
    "\n",
    "restaurant_test_positive = restaurant_test[restaurant_test['polarity'] == 'positive']\n",
    "restaurant_test_negative = restaurant_test[restaurant_test['polarity'] == 'negative']\n",
    "restaurant_test_neutral = restaurant_test[restaurant_test['polarity'] == 'neutral']\n",
    "\n",
    "print('      ','pos','neg','neutral')\n",
    "print('train', len(train_data_positive), len(train_data_negative), len(train_data_neutral))\n",
    "print('laptop', len(laptop_test_positive), len(laptop_test_negative), len(laptop_test_neutral))\n",
    "print('restau', len(restaurant_test_positive), len(restaurant_test_negative), len(restaurant_test_neutral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>positive</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech support would not fix the problem unless ...</td>\n",
       "      <td>tech support</td>\n",
       "      <td>negative</td>\n",
       "      <td>tech support</td>\n",
       "      <td>tech support would not fix the problem unless ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set up was easy.</td>\n",
       "      <td>Set up</td>\n",
       "      <td>positive</td>\n",
       "      <td>Set up</td>\n",
       "      <td>Set up was easy.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>Windows 8</td>\n",
       "      <td>negative</td>\n",
       "      <td>Did not enjoy the new Windows 8</td>\n",
       "      <td>Windows 8 and touchscreen functions.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>touchscreen functions</td>\n",
       "      <td>negative</td>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>touchscreen functions.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>internal speakers</td>\n",
       "      <td>negative</td>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>internal speakers, it's hard for me to find th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>price tag</td>\n",
       "      <td>positive</td>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>price tag.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>click pads</td>\n",
       "      <td>negative</td>\n",
       "      <td>Other than not being a fan of click pads</td>\n",
       "      <td>click pads (industry standard these days) and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No installation disk (DVD) is included.</td>\n",
       "      <td>installation disk (DVD)</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No installation disk (DVD)</td>\n",
       "      <td>installation disk (DVD) is included.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's fast, light, and simple to use.</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>It's fast, light, and simple to use</td>\n",
       "      <td>use.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   aspect  \\\n",
       "0  Boot time is super fast, around anywhere from ...                Boot time   \n",
       "1  tech support would not fix the problem unless ...             tech support   \n",
       "2                                   Set up was easy.                   Set up   \n",
       "3  Did not enjoy the new Windows 8 and touchscree...                Windows 8   \n",
       "4  Did not enjoy the new Windows 8 and touchscree...    touchscreen functions   \n",
       "5  Other than not being a fan of click pads (indu...        internal speakers   \n",
       "6  Other than not being a fan of click pads (indu...                price tag   \n",
       "7  Other than not being a fan of click pads (indu...               click pads   \n",
       "8            No installation disk (DVD) is included.  installation disk (DVD)   \n",
       "9               It's fast, light, and simple to use.                      use   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0  positive                                          Boot time   \n",
       "1  negative                                       tech support   \n",
       "2  positive                                             Set up   \n",
       "3  negative                    Did not enjoy the new Windows 8   \n",
       "4  negative  Did not enjoy the new Windows 8 and touchscree...   \n",
       "5  negative  Other than not being a fan of click pads (indu...   \n",
       "6  positive  Other than not being a fan of click pads (indu...   \n",
       "7  negative           Other than not being a fan of click pads   \n",
       "8   neutral                         No installation disk (DVD)   \n",
       "9  positive                It's fast, light, and simple to use   \n",
       "\n",
       "                                          right_text  label  \n",
       "0  Boot time is super fast, around anywhere from ...      2  \n",
       "1  tech support would not fix the problem unless ...      0  \n",
       "2                                   Set up was easy.      2  \n",
       "3               Windows 8 and touchscreen functions.      0  \n",
       "4                             touchscreen functions.      0  \n",
       "5  internal speakers, it's hard for me to find th...      0  \n",
       "6                                         price tag.      2  \n",
       "7  click pads (industry standard these days) and ...      0  \n",
       "8               installation disk (DVD) is included.      1  \n",
       "9                                               use.      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把polarity變成數字的label，positive是2，neutral是1，negative是0\n",
    "train_data.loc[train_data['polarity']=='positive', 'label'] = 2\n",
    "train_data.loc[train_data['polarity']=='negative', 'label'] = 0\n",
    "train_data.loc[train_data['polarity']=='neutral', 'label'] = 1\n",
    "train_data['label'] = train_data['label'].astype(int)\n",
    "\n",
    "laptop_test.loc[laptop_test['polarity']=='positive', 'label'] = 2\n",
    "laptop_test.loc[laptop_test['polarity']=='negative', 'label'] = 0\n",
    "laptop_test.loc[laptop_test['polarity']=='neutral', 'label'] = 1\n",
    "laptop_test['label'] = laptop_test['label'].astype(int)\n",
    "\n",
    "restaurant_test.loc[restaurant_test['polarity']=='positive', 'label'] = 2\n",
    "restaurant_test.loc[restaurant_test['polarity']=='negative', 'label'] = 0\n",
    "restaurant_test.loc[restaurant_test['polarity']=='neutral', 'label'] = 1\n",
    "restaurant_test['label'] = restaurant_test['label'].astype(int)\n",
    "\n",
    "laptop_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出最多字的cell是幾個字的function，用來判斷bert的維度要用多少\n",
    "def find_max_word(df):\n",
    "    max_count = 0\n",
    "    for i in tqdm(range(len(df))):\n",
    "        left_text_word_count = len(df.loc[i,'left_text'].split())\n",
    "        right_text_word_count = len(df.loc[i,'right_text'].split())\n",
    "        big_count = max(left_text_word_count, right_text_word_count)\n",
    "        if big_count>max_count:\n",
    "            max_count = big_count\n",
    "    return max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5915/5915 [00:00<00:00, 88776.52it/s]\n",
      "100%|██████████| 638/638 [00:00<00:00, 87552.87it/s]\n",
      "100%|██████████| 1120/1120 [00:00<00:00, 87059.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集字數最多是: 72\n",
      "laptop測試資料集字數最多是: 60\n",
      "restaurant測試資料集字數最多是: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 找出left text跟right text中字數最多的是幾個字\n",
    "train_max_count = find_max_word(train_data)\n",
    "laptop_test_max_count = find_max_word(laptop_test)\n",
    "restaurant_test_max_count = find_max_word(restaurant_test)\n",
    "print('訓練資料集字數最多是:',train_max_count)\n",
    "print('laptop測試資料集字數最多是:',laptop_test_max_count)\n",
    "print('restaurant測試資料集字數最多是:',restaurant_test_max_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert轉資料小小測試一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel, TFBertForSequenceClassification, TFBertModel\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, InputLayer\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer, to convert our text into tokens that correspond to BERT’s vocabulary.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.loc[4,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['the', 'tech', 'guy', 'then', 'said', 'the', 'service', 'center',\n",
       "       'does', 'not', 'do', '1', '-', 'to', '-', '1', 'exchange', 'and',\n",
       "       'i', 'have', 'to', 'direct', 'my', 'concern', 'to', 'the', '\"',\n",
       "       'sales', '\"', 'team', ',', 'which', 'is', 'the', 'retail', 'shop',\n",
       "       'which', 'i', 'bought', 'my', 'net', '##book', 'from', '.'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把句子切成一個一個單字或符號\n",
    "text = train_data.loc[4, 'text']\n",
    "print(text)\n",
    "tokens = tokenizer.tokenize(text)      # 每個字切詞成一個list\n",
    "print(type(tokens))                 # list\n",
    "np.array(tokens)                    # 轉成numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1996, 6627, 3124, 2059, 2056, 1996, 2326, 2415, 2515, 2025, 2079,\n",
       "       1015, 1011, 2000, 1011, 1015, 3863, 1998, 1045, 2031, 2000, 3622,\n",
       "       2026, 5142, 2000, 1996, 1000, 4341, 1000, 2136, 1010, 2029, 2003,\n",
       "       1996, 7027, 4497, 2029, 1045, 4149, 2026, 5658, 8654, 2013, 1012])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把英文單字或符號轉換成數字token，成為token list\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)   # 每個字轉成id\n",
    "print(type(input_ids))                         # list\n",
    "print(len(input_ids))\n",
    "np.array(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 101, 1996, 6627, 3124, 2059, 2056, 1996, 2326, 2415, 2515, 2025,\n",
       "       2079, 1015, 1011, 2000, 1011, 1015, 3863, 1998, 1045, 2031, 2000,\n",
       "       3622, 2026, 5142, 2000, 1996, 1000, 4341, 1000, 2136, 1010, 2029,\n",
       "       2003, 1996, 7027, 4497, 2029, 1045, 4149, 2026, 5658, 8654, 2013,\n",
       "       1012,  102])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把token list加上 CLS、SEP(起始跟結束的token)\n",
    "input_ids = tokenizer.build_inputs_with_special_tokens(input_ids)    # 句子前後加上 CLS SEP 的 id\n",
    "print(type(input_ids))\n",
    "print(len(input_ids))\n",
    "np.array(input_ids)\n",
    "# 101是CLS，101是SEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 101, 1996, 6627, 3124, 2059, 2056, 1996, 2326, 2415, 2515, 2025,\n",
       "       2079, 1015, 1011, 2000, 1011, 1015, 3863, 1998, 1045, 2031, 2000,\n",
       "       3622, 2026, 5142, 2000, 1996, 1000, 4341, 1000, 2136, 1010, 2029,\n",
       "       2003, 1996, 7027, 4497, 2029, 1045, 4149, 2026, 5658, 8654, 2013,\n",
       "       1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把每一個input句子都設成128維度，不夠補0\n",
    "input_dim = 128 #預設維度\n",
    "n = input_dim - len(input_ids)\n",
    "input_ids2 = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0))  # array右邊append n 個 0  補長度到128\n",
    "print(len(input_ids2))\n",
    "input_ids2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把上述處理建立一個function，丟入一串文字試試 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把維度固定在128維\n",
    "input_dim = 128\n",
    "def input_ids_all(text):\n",
    "#     if len(text) > input_dim-2:\n",
    "#         text = text[0:126]        \n",
    "    tokens = tokenizer.tokenize(text)                          # 每個字切詞成一個list\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)        # 每個字轉成id\n",
    "    input_ids = tokenizer.build_inputs_with_special_tokens(input_ids)    # 句子前後加上 CLS SEP 的 id\n",
    "    input_ids = np.array(input_ids)                            # list 轉 numpy\n",
    "    if len(input_ids) < input_dim:\n",
    "        n = input_dim - len(input_ids)\n",
    "        input_ids = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0))    # array右邊append n 個 0  補長度到512\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 101, 1996, 6627, 3124, 2059, 2056, 1996, 2326, 2415, 2515, 2025,\n",
       "       2079, 1015, 1011, 2000, 1011, 1015, 3863, 1998, 1045, 2031, 2000,\n",
       "       3622, 2026, 5142, 2000, 1996, 1000, 4341, 1000, 2136, 1010, 2029,\n",
       "       2003, 1996, 7027, 4497, 2029, 1045, 4149, 2026, 5658, 8654, 2013,\n",
       "       1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = 'The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.'\n",
    "print(text)\n",
    "input_ids_all(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正式把資料餵進模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_left_text資料數: 5915\n",
      "train_right_text資料數: 5915\n",
      "laptop_left_text資料數: 638\n",
      "laptop_right_text資料數: 638\n",
      "restaurant_left_text資料數: 1120\n",
      "restaurant_right_text資料數: 1120\n",
      "\n",
      "第一筆train_left_text: I charge it at night and skip taking the cord\n",
      "資料型態: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#轉成numpy\n",
    "train_left_text = train_data['left_text'].to_numpy()\n",
    "train_right_text = train_data['right_text'].to_numpy()\n",
    "\n",
    "laptop_left_text = laptop_test['left_text'].to_numpy()\n",
    "laptop_right_text = laptop_test['right_text'].to_numpy()\n",
    "\n",
    "restaurant_left_text = restaurant_test['left_text'].to_numpy()\n",
    "restaurant_right_text = restaurant_test['right_text'].to_numpy()\n",
    "\n",
    "print('train_left_text資料數:',len(train_left_text))\n",
    "print('train_right_text資料數:',len(train_right_text))\n",
    "print('laptop_left_text資料數:',len(laptop_left_text))\n",
    "print('laptop_right_text資料數:',len(laptop_right_text))\n",
    "print('restaurant_left_text資料數:',len(restaurant_left_text))\n",
    "print('restaurant_right_text資料數:',len(restaurant_right_text))\n",
    "print()\n",
    "print('第一筆train_left_text:',train_left_text[0])\n",
    "print('資料型態:',type(train_left_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_left_input_ids資料數: 5915\n",
      "train_right_input_ids資料數: 5915\n",
      "laptop_left_input_ids資料數: 638\n",
      "laptop_right_input_ids資料數: 638\n",
      "restaurant_left_input_ids資料數: 1120\n",
      "restaurant_right_input_ids資料數: 1120\n",
      "\n",
      "[ 101 1996 6627 3124  102    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[ 101 6627 3124 2059 2056 1996 2326 2415 2515 2025 2079 1015 1011 2000\n",
      " 1011 1015 3863 1998 1045 2031 2000 3622 2026 5142 2000 1996 1000 4341\n",
      " 1000 2136 1010 2029 2003 1996 7027 4497 2029 1045 4149 2026 5658 8654\n",
      " 2013 1012  102    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 把train、laptop_test、restaurant_test 的input改成token、numpy格式\n",
    "train_left_input_ids = [input_ids_all(i) for i in train_left_text]      # 必須要 [ ] 輸出是list\n",
    "train_left_input_ids = np.array(train_left_input_ids)                    # 轉成numpy\n",
    "\n",
    "train_right_input_ids = [input_ids_all(i) for i in train_right_text]\n",
    "train_right_input_ids = np.array(train_right_input_ids)\n",
    "\n",
    "laptop_left_input_ids = [input_ids_all(i) for i in laptop_left_text]\n",
    "laptop_left_input_ids = np.array(laptop_left_input_ids)\n",
    "\n",
    "laptop_right_input_ids = [input_ids_all(i) for i in laptop_right_text]\n",
    "laptop_right_input_ids = np.array(laptop_right_input_ids)\n",
    "\n",
    "restaurant_left_input_ids = [input_ids_all(i) for i in restaurant_left_text]\n",
    "restaurant_left_input_ids = np.array(restaurant_left_input_ids)\n",
    "\n",
    "restaurant_right_input_ids = [input_ids_all(i) for i in restaurant_right_text]\n",
    "restaurant_right_input_ids = np.array(restaurant_right_input_ids)\n",
    "\n",
    "print('train_left_input_ids資料數:',len(train_left_input_ids))\n",
    "print('train_right_input_ids資料數:',len(train_right_input_ids))\n",
    "print('laptop_left_input_ids資料數:',len(laptop_left_input_ids))\n",
    "print('laptop_right_input_ids資料數:',len(laptop_right_input_ids))\n",
    "print('restaurant_left_input_ids資料數:',len(restaurant_left_input_ids))\n",
    "print('restaurant_right_input_ids資料數:',len(restaurant_right_input_ids))\n",
    "print()\n",
    "print(train_left_input_ids[4])\n",
    "print(train_right_input_ids[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 ... 1 1 1]\n",
      "5915\n",
      "638\n",
      "1120\n"
     ]
    }
   ],
   "source": [
    "# 把train、laptop_test、restaurant_test 的label改成numpy\n",
    "train_label = train_data['label'].to_numpy()\n",
    "laptop_label = laptop_test['label'].to_numpy()\n",
    "restaurant_label = restaurant_test['label'].to_numpy()\n",
    "print(train_label)\n",
    "print(len(train_label))\n",
    "print(len(laptop_label))\n",
    "print(len(restaurant_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 2 2\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "neutral 1 1\n",
      "positive 2 2\n",
      "\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "neutral 1 1\n"
     ]
    }
   ],
   "source": [
    "# 檢查polarity跟label有沒有不一樣\n",
    "for i in range(10):\n",
    "    print(laptop_test.loc[i, 'polarity'], laptop_test.loc[i, 'label'], laptop_label[i])\n",
    "print()\n",
    "for i in range(11):\n",
    "    print(restaurant_test.loc[i, 'polarity'], restaurant_test.loc[i, 'label'], restaurant_label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel)   ((None, 128, 768), ( 109482240   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_3 (TFBertModel)   ((None, 128, 768), ( 109482240   input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 98304)        0           tf_bert_model_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 98304)        0           tf_bert_model_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 196608)       0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            589827      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 219,554,307\n",
      "Trainable params: 219,554,307\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# first input model\n",
    "input_layer_1 = Input(shape = (128,), dtype='int64')\n",
    "bert_model_1 = TFBertModel.from_pretrained('bert-base-uncased')(input_layer_1)\n",
    "bert_model_1 = bert_model_1[0]\n",
    "dropout_1 = Dropout(0.1)(bert_model_1)\n",
    "flat1 = Flatten()(bert_model_1)\n",
    "\n",
    "# second input model\n",
    "input_layer_2 = Input(shape = (128,), dtype='int64')\n",
    "bert_model_2 = TFBertModel.from_pretrained('bert-base-uncased')(input_layer_2)\n",
    "bert_model_2 = bert_model_2[0]\n",
    "dropout = Dropout(0.1)(bert_model_2)\n",
    "flat2 = Flatten()(bert_model_2)\n",
    "\n",
    "\n",
    "merge = concatenate([flat1, flat2]) # merge input model\n",
    "output = Dense(units=3, activation = 'softmax')(merge)\n",
    "model = Model(inputs=[input_layer_1, input_layer_2], outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=7e-6, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 638 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "5915/5915 [==============================] - 196s 33ms/sample - loss: 1.0192 - accuracy: 0.5319 - val_loss: 1.0170 - val_accuracy: 0.5345\n",
      "Epoch 2/5\n",
      "5915/5915 [==============================] - 176s 30ms/sample - loss: 1.0187 - accuracy: 0.5327 - val_loss: 1.0170 - val_accuracy: 0.5345\n",
      "Epoch 3/5\n",
      "5915/5915 [==============================] - 176s 30ms/sample - loss: 1.0187 - accuracy: 0.5327 - val_loss: 1.0169 - val_accuracy: 0.5345\n",
      "Epoch 4/5\n",
      "5915/5915 [==============================] - 176s 30ms/sample - loss: 1.0188 - accuracy: 0.5327 - val_loss: 1.0170 - val_accuracy: 0.5345\n",
      "Epoch 5/5\n",
      "1612/5915 [=======>......................] - ETA: 2:03 - loss: 1.0079 - accuracy: 0.5435"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-65f4f2d0a07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_fit = model.fit([train_left_input_ids,train_right_input_ids], train_label, \n\u001b[1;32m      2\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlaptop_left_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlaptop_right_input_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaptop_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#                      steps_per_epoch=115,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#                      validation_steps=7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_data、laptop_test\n",
    "model_fit = model.fit([train_left_input_ids,train_right_input_ids], train_label, \n",
    "                      batch_size=4, epochs=5, \n",
    "                      validation_data=([laptop_left_input_ids,laptop_right_input_ids], laptop_label)\n",
    "#                      steps_per_epoch=115,\n",
    "#                      validation_steps=7)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1120 samples\n",
      "Epoch 1/5\n",
      "5915/5915 [==============================] - 180s 30ms/sample - loss: 1.0187 - accuracy: 0.5327 - val_loss: 0.9014 - val_accuracy: 0.6500\n",
      "Epoch 2/5\n",
      "5915/5915 [==============================] - 178s 30ms/sample - loss: 1.0187 - accuracy: 0.5327 - val_loss: 0.9014 - val_accuracy: 0.6500\n",
      "Epoch 3/5\n",
      "5152/5915 [=========================>....] - ETA: 21s - loss: 1.0204 - accuracy: 0.5299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2236b92c9230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_fit = model.fit([train_left_input_ids,train_right_input_ids], train_label, \n\u001b[1;32m      2\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrestaurant_left_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestaurant_right_input_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestaurant_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#                      steps_per_epoch=115,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#                      validation_steps=7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/bertenv2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_data、restaurant_test\n",
    "model_fit = model.fit([train_left_input_ids,train_right_input_ids], train_label, \n",
    "                      batch_size=4, epochs=5, \n",
    "                      validation_data=([restaurant_left_input_ids,restaurant_right_input_ids], restaurant_label)\n",
    "#                      steps_per_epoch=115,\n",
    "#                      validation_steps=7)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
