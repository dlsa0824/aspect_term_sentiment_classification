{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先跑LSTM抓取feature(把hidden layer抽出來)，再放到bert裡面去做分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對處理好的laptop、restaurant的train、test資料作前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把dataframe裡的text切成text左邊跟右邊並做一些處理的function\n",
    "def split_text(df):\n",
    "    df['left_text'] = 'N/A'\n",
    "    df['right_text'] = 'N/A'\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        text = df.loc[i, 'text']\n",
    "        aspect = df.loc[i, 'aspect']\n",
    "        text_split = text.split(aspect) # 根據aspect切割text左右邊\n",
    "        \n",
    "        left_text = text_split[0]+aspect\n",
    "        right_text = aspect+text_split[1]\n",
    "        left_text = left_text.lower() # 把字串變成小寫\n",
    "        right_text = right_text.lower()\n",
    "        left_text = re.sub('-', ' ', left_text)\n",
    "        right_text = re.sub('-', ' ', right_text)\n",
    "        left_text = re.sub('[.,!\"()#%&/:?~]', '', left_text) # 把字串中的一些符號刪除\n",
    "        right_text = re.sub('[.,!\"()#%&/:?~]', '', right_text)\n",
    "        \n",
    "        df.loc[i,'left_text'] = left_text\n",
    "        df.loc[i,'right_text'] = right_text\n",
    "        df.loc[i, 'left_right_text'] = left_text +' '+ right_text # 用來文字encoding\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7673/7673 [00:02<00:00, 2903.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集: 5915\n",
      "測試資料集: 1758\n",
      "所有資料集: 7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i charge it at night and skip taking the cord</td>\n",
       "      <td>cord with me because of the good battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center</td>\n",
       "      <td>service center does not do 1 to 1 exchange and...</td>\n",
       "      <td>the tech guy then said the service center serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>sales team which is the retail shop which i bo...</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the tech guy</td>\n",
       "      <td>tech guy then said the service center does not...</td>\n",
       "      <td>the tech guy tech guy then said the service ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>quality</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality</td>\n",
       "      <td>quality has a killer gui is extremely stable i...</td>\n",
       "      <td>it is of high quality quality has a killer gui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>GUI</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui</td>\n",
       "      <td>gui is extremely stable is highly expandable i...</td>\n",
       "      <td>it is of high quality has a killer gui gui is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>applications</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>applications is easy to use and is absolutely ...</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>use and is absolutely gorgeous</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Easy to start up and does not overheat as much...</td>\n",
       "      <td>start up</td>\n",
       "      <td>positive</td>\n",
       "      <td>easy to start up</td>\n",
       "      <td>start up and does not overheat as much as othe...</td>\n",
       "      <td>easy to start up start up and does not overhea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          aspect  \\\n",
       "0  I charge it at night and skip taking the cord ...            cord   \n",
       "1  I charge it at night and skip taking the cord ...    battery life   \n",
       "2  The tech guy then said the service center does...  service center   \n",
       "3  The tech guy then said the service center does...    \"sales\" team   \n",
       "4  The tech guy then said the service center does...        tech guy   \n",
       "5  it is of high quality, has a killer GUI, is ex...         quality   \n",
       "6  it is of high quality, has a killer GUI, is ex...             GUI   \n",
       "7  it is of high quality, has a killer GUI, is ex...    applications   \n",
       "8  it is of high quality, has a killer GUI, is ex...             use   \n",
       "9  Easy to start up and does not overheat as much...        start up   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0   neutral      i charge it at night and skip taking the cord   \n",
       "1  positive  i charge it at night and skip taking the cord ...   \n",
       "2  negative          the tech guy then said the service center   \n",
       "3  negative  the tech guy then said the service center does...   \n",
       "4   neutral                                       the tech guy   \n",
       "5  positive                              it is of high quality   \n",
       "6  positive             it is of high quality has a killer gui   \n",
       "7  positive  it is of high quality has a killer gui is extr...   \n",
       "8  positive  it is of high quality has a killer gui is extr...   \n",
       "9  positive                                   easy to start up   \n",
       "\n",
       "                                          right_text  \\\n",
       "0      cord with me because of the good battery life   \n",
       "1                                       battery life   \n",
       "2  service center does not do 1 to 1 exchange and...   \n",
       "3  sales team which is the retail shop which i bo...   \n",
       "4  tech guy then said the service center does not...   \n",
       "5  quality has a killer gui is extremely stable i...   \n",
       "6  gui is extremely stable is highly expandable i...   \n",
       "7  applications is easy to use and is absolutely ...   \n",
       "8                     use and is absolutely gorgeous   \n",
       "9  start up and does not overheat as much as othe...   \n",
       "\n",
       "                                     left_right_text  \n",
       "0  i charge it at night and skip taking the cord ...  \n",
       "1  i charge it at night and skip taking the cord ...  \n",
       "2  the tech guy then said the service center serv...  \n",
       "3  the tech guy then said the service center does...  \n",
       "4  the tech guy tech guy then said the service ce...  \n",
       "5  it is of high quality quality has a killer gui...  \n",
       "6  it is of high quality has a killer gui gui is ...  \n",
       "7  it is of high quality has a killer gui is extr...  \n",
       "8  it is of high quality has a killer gui is extr...  \n",
       "9  easy to start up start up and does not overhea...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_train = pd.read_csv('dataset/laptop_train_processed.csv', encoding='utf-8')\n",
    "restaurant_train = pd.read_csv('dataset/restaurant_train_processed.csv', encoding='utf-8')\n",
    "laptop_test = pd.read_csv('dataset/laptop_test_processed.csv', encoding='utf-8')\n",
    "restaurant_test = pd.read_csv('dataset/restaurant_test_processed.csv', encoding='utf-8')\n",
    "\n",
    "# 把train的資料串在一起\n",
    "train_data = laptop_train.append(restaurant_train)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "#把test的資料串在一起\n",
    "test_data = laptop_test.append(restaurant_test)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "#把train、test資料串在一起\n",
    "data = train_data.append(test_data)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# data切割text\n",
    "data = split_text(data)\n",
    "\n",
    "print('訓練資料集:', len(train_data))\n",
    "print('測試資料集:', len(test_data))\n",
    "print('所有資料集:', len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.\n",
      "\n",
      "the tech guy then said the service center does not do 1 to 1 exchange and i have to direct my concern to the sales team\n",
      "\n",
      "sales team which is the retail shop which i bought my netbook from\n",
      "\n",
      "the tech guy then said the service center does not do 1 to 1 exchange and i have to direct my concern to the sales team sales team which is the retail shop which i bought my netbook from\n"
     ]
    }
   ],
   "source": [
    "# print一個出來看看\n",
    "n = 3\n",
    "print(data.loc[n, 'text'])\n",
    "print()\n",
    "print(data.loc[n, 'left_text'])\n",
    "print()\n",
    "print(data.loc[n, 'right_text'])\n",
    "print()\n",
    "print(data.loc[n, 'left_right_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i charge it at night and skip taking the cord</td>\n",
       "      <td>cord with me because of the good battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center</td>\n",
       "      <td>service center does not do 1 to 1 exchange and...</td>\n",
       "      <td>the tech guy then said the service center serv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>sales team which is the retail shop which i bo...</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the tech guy</td>\n",
       "      <td>tech guy then said the service center does not...</td>\n",
       "      <td>the tech guy tech guy then said the service ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>quality</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality</td>\n",
       "      <td>quality has a killer gui is extremely stable i...</td>\n",
       "      <td>it is of high quality quality has a killer gui...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>GUI</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui</td>\n",
       "      <td>gui is extremely stable is highly expandable i...</td>\n",
       "      <td>it is of high quality has a killer gui gui is ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>applications</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>applications is easy to use and is absolutely ...</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>use and is absolutely gorgeous</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Easy to start up and does not overheat as much...</td>\n",
       "      <td>start up</td>\n",
       "      <td>positive</td>\n",
       "      <td>easy to start up</td>\n",
       "      <td>start up and does not overheat as much as othe...</td>\n",
       "      <td>easy to start up start up and does not overhea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          aspect  \\\n",
       "0  I charge it at night and skip taking the cord ...            cord   \n",
       "1  I charge it at night and skip taking the cord ...    battery life   \n",
       "2  The tech guy then said the service center does...  service center   \n",
       "3  The tech guy then said the service center does...    \"sales\" team   \n",
       "4  The tech guy then said the service center does...        tech guy   \n",
       "5  it is of high quality, has a killer GUI, is ex...         quality   \n",
       "6  it is of high quality, has a killer GUI, is ex...             GUI   \n",
       "7  it is of high quality, has a killer GUI, is ex...    applications   \n",
       "8  it is of high quality, has a killer GUI, is ex...             use   \n",
       "9  Easy to start up and does not overheat as much...        start up   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0   neutral      i charge it at night and skip taking the cord   \n",
       "1  positive  i charge it at night and skip taking the cord ...   \n",
       "2  negative          the tech guy then said the service center   \n",
       "3  negative  the tech guy then said the service center does...   \n",
       "4   neutral                                       the tech guy   \n",
       "5  positive                              it is of high quality   \n",
       "6  positive             it is of high quality has a killer gui   \n",
       "7  positive  it is of high quality has a killer gui is extr...   \n",
       "8  positive  it is of high quality has a killer gui is extr...   \n",
       "9  positive                                   easy to start up   \n",
       "\n",
       "                                          right_text  \\\n",
       "0      cord with me because of the good battery life   \n",
       "1                                       battery life   \n",
       "2  service center does not do 1 to 1 exchange and...   \n",
       "3  sales team which is the retail shop which i bo...   \n",
       "4  tech guy then said the service center does not...   \n",
       "5  quality has a killer gui is extremely stable i...   \n",
       "6  gui is extremely stable is highly expandable i...   \n",
       "7  applications is easy to use and is absolutely ...   \n",
       "8                     use and is absolutely gorgeous   \n",
       "9  start up and does not overheat as much as othe...   \n",
       "\n",
       "                                     left_right_text  label  \n",
       "0  i charge it at night and skip taking the cord ...      1  \n",
       "1  i charge it at night and skip taking the cord ...      2  \n",
       "2  the tech guy then said the service center serv...      0  \n",
       "3  the tech guy then said the service center does...      0  \n",
       "4  the tech guy tech guy then said the service ce...      1  \n",
       "5  it is of high quality quality has a killer gui...      2  \n",
       "6  it is of high quality has a killer gui gui is ...      2  \n",
       "7  it is of high quality has a killer gui is extr...      2  \n",
       "8  it is of high quality has a killer gui is extr...      2  \n",
       "9  easy to start up start up and does not overhea...      2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把文字Label變成數字label\n",
    "data.loc[data['polarity'] == 'positive', 'label'] = 2\n",
    "data.loc[data['polarity'] == 'neutral', 'label'] = 1\n",
    "data.loc[data['polarity'] == 'negative', 'label'] = 0\n",
    "data['label'] = data['label'].astype(int)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_text與right_text最多的字數: 72\n"
     ]
    }
   ],
   "source": [
    "#找出left_text跟right_text裡面最多是多少字\n",
    "max_count = 0\n",
    "for i in range(len(data)):\n",
    "    left_text_word_count = len(data.loc[i,'left_text'].split())\n",
    "    right_text_word_count = len(data.loc[i,'right_text'].split())\n",
    "    big_count = max(left_text_word_count, right_text_word_count)\n",
    "    if big_count>max_count:\n",
    "        max_count = big_count\n",
    "print('left_text與right_text最多的字數:', max_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對文字做encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 7000 # 最大的字數\n",
    "max_seq_length = 80 # 句子最長長度\n",
    "embedding_dim = 300 # 每個字維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6557 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# 把字變成token\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(data['left_right_text'].to_numpy())\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "# word_index就是根據left_right_text內容彙整出來的切字跟代表那個字的token number (每個字的dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : 1\n",
      "and : 2\n",
      "a : 3\n",
      "to : 4\n",
      "is : 5\n",
      "i : 6\n",
      "of : 7\n",
      "for : 8\n",
      "food : 9\n",
      "it : 10\n"
     ]
    }
   ],
   "source": [
    "# 檢查word_index(dictionary)裡面的東西，前面是字，後面是token\n",
    "for x in list(word_index)[0:10]:\n",
    "    print (x, ':', word_index[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy to start up\n",
      "start up and does not overheat as much as other laptops\n",
      "[119, 4, 588, 52]\n",
      "[588, 52, 2, 213, 22, 5291, 30, 125, 30, 86, 509]\n",
      "<class 'list'>\n",
      "right text 倒過來\n",
      "[119, 4, 588, 52]\n",
      "[509, 86, 30, 125, 30, 5291, 22, 213, 2, 52, 588]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 檢查其中一項字串的token\n",
    "n = 9 # index number\n",
    "left_text = data['left_text'].to_numpy() # 轉成向量\n",
    "right_text = data['right_text'].to_numpy()\n",
    "left_text_seq = tokenizer.texts_to_sequences(left_text)\n",
    "right_text_seq = tokenizer.texts_to_sequences(right_text)\n",
    "print(data.loc[n, 'left_text'])\n",
    "print(data.loc[n, 'right_text'])\n",
    "print(left_text_seq[n])\n",
    "print(right_text_seq[n])\n",
    "print(type(right_text_seq))\n",
    "# 把右邊的字串token倒過來，因為要從後面讀到前面\n",
    "print('right text 倒過來')\n",
    "for i in range(len(right_text_seq)):\n",
    "    right_text_seq[i] = right_text_seq[i][::-1]\n",
    "print(left_text_seq[n])\n",
    "print(right_text_seq[n])\n",
    "print(type(right_text_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119   4 588  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "[ 509   86   30  125   30 5291   22  213    2   52  588    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# token sequence 後面補0的方法\n",
    "def text_seq_padding(text_seq):\n",
    "    if len(text_seq) < max_seq_length:\n",
    "        n = max_seq_length - len(text_seq)\n",
    "        text_seq = np.pad(text_seq, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0\n",
    "    return text_seq\n",
    "# 把每個left_text_seq，right_text_seq padding到同樣的長度 (後面補0)\n",
    "left_text_seq = [text_seq_padding(i) for i in left_text_seq] # 必須要 [ ] 輸出是list\n",
    "left_text_seq = np.array(left_text_seq)\n",
    "\n",
    "right_text_seq = [text_seq_padding(i) for i in right_text_seq]\n",
    "right_text_seq = np.array(right_text_seq)\n",
    "\n",
    "# n = 0 # index number\n",
    "print(left_text_seq[n])\n",
    "print(right_text_seq[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用預先處理的詞向量 (crawl 300 dim)\n",
    "#### https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6558, 300)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.0231      0.017       0.0157     ...  0.0744     -0.1118\n",
      "   0.0963    ]\n",
      " [-0.1081      0.0191      0.0354     ...  0.1104      0.0475\n",
      "  -0.0599    ]\n",
      " ...\n",
      " [ 0.16580001 -0.0169     -0.4138     ...  0.0933     -0.1168\n",
      "  -0.1777    ]\n",
      " [-0.1179      0.0726     -0.005      ...  0.2079      0.0322\n",
      "  -0.26879999]\n",
      " [ 0.24439999  0.1206      0.1123     ... -0.147      -0.0186\n",
      "  -0.3204    ]]\n"
     ]
    }
   ],
   "source": [
    "# 把embedding_matrix load 近來\n",
    "embedding_matrix = np.load('dataset/embedding_matrix.npy')\n",
    "print(type(embedding_matrix))\n",
    "print(embedding_matrix.shape)\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認資料、並切割成train、test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boot time\n",
      "boot time is super fast around anywhere from 35 seconds to 1 minute\n",
      "[500  98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "[1318  434    4 1017 2018   44  844  261  139  532    5   98  500    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "the bread\n",
      "bread is top notch as well\n",
      "[  1 309   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "[  71   30 1061  359    5  309    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 稽查dataframe、token sequence裡面laptop_test、restaurant_test資料是否一致\n",
    "# laptop_test第一筆在5915；restaurant_test第一筆在6553\n",
    "print(data.loc[5915, 'left_text'])\n",
    "print(data.loc[5915, 'right_text'])\n",
    "print(left_text_seq[5915])\n",
    "print(right_text_seq[5915])\n",
    "print()\n",
    "print(data.loc[6553, 'left_text'])\n",
    "print(data.loc[6553, 'right_text'])\n",
    "print(left_text_seq[6553])\n",
    "print(right_text_seq[6553])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (7673,)\n",
      "1 1\n",
      "2 2\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "# 把label轉成numpy\n",
    "Y = data['label'].to_numpy()\n",
    "print('Shape of Y:', Y.shape)\n",
    "for i in range(10):\n",
    "    print(data.loc[i, 'label'], Y[i])\n",
    "#[1 0 0] = negative\n",
    "#[0 1 0] = neutral\n",
    "#[0 0 1] = positve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5915 5915 5915\n",
      "1758 1758 1758\n"
     ]
    }
   ],
   "source": [
    "#把資料切割成train、test\n",
    "X_left_train = left_text_seq[:5915]\n",
    "X_right_train = right_text_seq[:5915]\n",
    "Y_train = Y[:5915]\n",
    "X_left_test = left_text_seq[5915:]\n",
    "X_right_test = right_text_seq[5915:]\n",
    "Y_test = Y[5915:]\n",
    "print(len(X_left_train), len(X_right_train), len(Y_train))\n",
    "print(len(X_left_test), len(X_right_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop_test     restaurant_test\n",
      "positive 2 2    positive 2 2\n",
      "negative 0 0    positive 2 2\n",
      "positive 2 2    positive 2 2\n",
      "negative 0 0    positive 2 2\n",
      "negative 0 0    positive 2 2\n",
      "negative 0 0    positive 2 2\n",
      "positive 2 2    positive 2 2\n",
      "negative 0 0    positive 2 2\n",
      "neutral 1 1    positive 2 2\n",
      "positive 2 2    positive 2 2\n",
      "positive 2 2    neutral 1 1\n",
      "positive 2 2    positive 2 2\n",
      "positive 2 2    positive 2 2\n",
      "positive 2 2    positive 2 2\n",
      "positive 2 2    negative 0 0\n",
      "positive 2 2    positive 2 2\n",
      "negative 0 0    neutral 1 1\n",
      "negative 0 0    neutral 1 1\n",
      "positive 2 2    positive 2 2\n",
      "positive 2 2    positive 2 2\n"
     ]
    }
   ],
   "source": [
    "# 檢查polarity跟label有沒有不一樣\n",
    "print('laptop_test', '   ','restaurant_test')\n",
    "for i in range(20):\n",
    "    print(laptop_test.loc[i, 'polarity'], data.loc[5915+i, 'label'], Y_test[i], '  ', restaurant_test.loc[i, 'polarity'], data.loc[6553+i, 'label'], Y_test[638+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, InputLayer, Bidirectional, concatenate, add, average, Reshape\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把兩邊input concate起來，有加上dropout的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 80, 300)      1967400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 80, 300)      1967400     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 512)          1665024     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 512)          1665024     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          131200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,404,499\n",
      "Trainable params: 7,404,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# first input model 1\n",
    "input_layer_1 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_1 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_1)\n",
    "lstm_hidden_1 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_1) \n",
    "# lstm_hidden_1 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_1) \n",
    "\n",
    "#second input model 2\n",
    "input_layer_2 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_2 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_2)\n",
    "lstm_hidden_2 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_2)\n",
    "# lstm_hidden_2 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_2)\n",
    "\n",
    "#merge input model\n",
    "averaged = concatenate([lstm_hidden_1, lstm_hidden_2])\n",
    "hidden_1 = Dense(128, activation='relu')(averaged)\n",
    "dropout_1 = Dropout(0.3)(hidden_1)\n",
    "hidden_2 = Dense(64, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.3)(hidden_2)\n",
    "output = Dense(3, activation='softmax')(dropout_2)\n",
    "model1 = Model(inputs=[input_layer_1, input_layer_2], outputs=output)\n",
    "print(model1.summary())\n",
    "adam = Adam(lr=1e-2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model1.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1758 samples\n",
      "Epoch 1/30\n",
      "5915/5915 [==============================] - 13s 2ms/sample - loss: 0.9265 - accuracy: 0.6174 - val_loss: 0.8424 - val_accuracy: 0.6951\n",
      "Epoch 2/30\n",
      "5915/5915 [==============================] - 4s 722us/sample - loss: 0.8215 - accuracy: 0.7222 - val_loss: 0.8157 - val_accuracy: 0.7281\n",
      "Epoch 3/30\n",
      "5915/5915 [==============================] - 4s 721us/sample - loss: 0.7849 - accuracy: 0.7616 - val_loss: 0.8112 - val_accuracy: 0.7327\n",
      "Epoch 4/30\n",
      "5915/5915 [==============================] - 4s 715us/sample - loss: 0.7324 - accuracy: 0.8150 - val_loss: 0.8187 - val_accuracy: 0.7281\n",
      "Epoch 5/30\n",
      "5915/5915 [==============================] - 6s 1ms/sample - loss: 0.7085 - accuracy: 0.8401 - val_loss: 0.8120 - val_accuracy: 0.7270\n",
      "Epoch 6/30\n",
      "5915/5915 [==============================] - 4s 719us/sample - loss: 0.6914 - accuracy: 0.8578 - val_loss: 0.8155 - val_accuracy: 0.7298\n",
      "Epoch 7/30\n",
      "5915/5915 [==============================] - 6s 1ms/sample - loss: 0.6829 - accuracy: 0.8668 - val_loss: 0.8143 - val_accuracy: 0.7315\n",
      "Epoch 8/30\n",
      "5915/5915 [==============================] - 4s 724us/sample - loss: 0.6709 - accuracy: 0.8781 - val_loss: 0.8083 - val_accuracy: 0.7344\n",
      "Epoch 9/30\n",
      "5915/5915 [==============================] - 4s 715us/sample - loss: 0.6559 - accuracy: 0.8935 - val_loss: 0.8305 - val_accuracy: 0.7144\n",
      "Epoch 10/30\n",
      "5915/5915 [==============================] - 5s 924us/sample - loss: 0.6505 - accuracy: 0.8991 - val_loss: 0.8014 - val_accuracy: 0.7440\n",
      "Epoch 11/30\n",
      "5915/5915 [==============================] - 4s 719us/sample - loss: 0.6396 - accuracy: 0.9107 - val_loss: 0.8054 - val_accuracy: 0.7400\n",
      "Epoch 12/30\n",
      "5915/5915 [==============================] - 6s 1ms/sample - loss: 0.6328 - accuracy: 0.9182 - val_loss: 0.8149 - val_accuracy: 0.7309\n",
      "Epoch 13/30\n",
      "5915/5915 [==============================] - 4s 715us/sample - loss: 0.6279 - accuracy: 0.9238 - val_loss: 0.8208 - val_accuracy: 0.7281\n",
      "Epoch 14/30\n",
      "5915/5915 [==============================] - 6s 1ms/sample - loss: 0.6288 - accuracy: 0.9222 - val_loss: 0.8155 - val_accuracy: 0.7321\n",
      "Epoch 15/30\n",
      "5915/5915 [==============================] - 4s 717us/sample - loss: 0.6263 - accuracy: 0.9256 - val_loss: 0.8152 - val_accuracy: 0.7344\n",
      "Epoch 16/30\n",
      "5915/5915 [==============================] - 6s 1ms/sample - loss: 0.6249 - accuracy: 0.9260 - val_loss: 0.8225 - val_accuracy: 0.7258\n",
      "Epoch 17/30\n",
      "5915/5915 [==============================] - 4s 723us/sample - loss: 0.6203 - accuracy: 0.9302 - val_loss: 0.8237 - val_accuracy: 0.7230\n",
      "Epoch 18/30\n",
      "5888/5915 [============================>.] - ETA: 0s - loss: 0.6175 - accuracy: 0.9333Restoring model weights from the end of the best epoch.\n",
      "5915/5915 [==============================] - 6s 1ms/sample - loss: 0.6176 - accuracy: 0.9332 - val_loss: 0.8141 - val_accuracy: 0.7361\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "model1_fit = model1.fit([X_left_train, X_right_train],Y_train, batch_size=64,epochs=30,\n",
    "                      validation_data=([X_left_test, X_right_test],Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三元分類還沒argmax output\n",
      "[[9.3566136e-08 9.4068973e-08 9.9999976e-01]\n",
      " [9.9720287e-01 2.1214650e-03 6.7564804e-04]\n",
      " [2.1758662e-09 4.6127449e-09 1.0000000e+00]\n",
      " ...\n",
      " [8.1276925e-20 8.8947807e-19 1.0000000e+00]\n",
      " [1.3840235e-19 1.8584126e-18 1.0000000e+00]\n",
      " [1.4807888e-14 1.3286274e-13 1.0000000e+00]]\n",
      "\n",
      "0.7440273037542662\n",
      "[[191  59  74]\n",
      " [ 65 163 137]\n",
      " [ 53  62 954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60       324\n",
      "           1       0.57      0.45      0.50       365\n",
      "           2       0.82      0.89      0.85      1069\n",
      "\n",
      "    accuracy                           0.74      1758\n",
      "   macro avg       0.67      0.64      0.65      1758\n",
      "weighted avg       0.73      0.74      0.73      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取所有label中的test label\n",
    "Y_label = data['label'].to_numpy()[5915:]\n",
    "\n",
    "# test data confusion matrix\n",
    "predictions= model1.predict([X_left_test, X_right_test]) # 輸出的是n*5的編碼值array\n",
    "print('三元分類還沒argmax output')\n",
    "print(predictions)\n",
    "print()\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(Y_label, predictions))\n",
    "print(confusion_matrix(Y_label, predictions))\n",
    "print(classification_report(Y_label, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6865203761755486\n",
      "[[ 68  34  26]\n",
      " [ 38  86  45]\n",
      " [ 21  36 284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53       128\n",
      "           1       0.55      0.51      0.53       169\n",
      "           2       0.80      0.83      0.82       341\n",
      "\n",
      "    accuracy                           0.69       638\n",
      "   macro avg       0.63      0.62      0.63       638\n",
      "weighted avg       0.68      0.69      0.68       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取所有label中的laptop test lable\n",
    "laptop_label = data['label'].to_numpy()[5915:6553]\n",
    "\n",
    "# laptop test data confusion matrix\n",
    "predictions= model1.predict([X_left_test[:638], X_right_test[:638]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(laptop_label, predictions))\n",
    "print(confusion_matrix(laptop_label, predictions))\n",
    "print(classification_report(laptop_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7767857142857143\n",
      "[[123  25  48]\n",
      " [ 27  77  92]\n",
      " [ 32  26 670]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65       196\n",
      "           1       0.60      0.39      0.48       196\n",
      "           2       0.83      0.92      0.87       728\n",
      "\n",
      "    accuracy                           0.78      1120\n",
      "   macro avg       0.70      0.65      0.67      1120\n",
      "weighted avg       0.76      0.78      0.76      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取所有label中的restaurant test lable\n",
    "restaurant_label = data['label'].to_numpy()[6553:]\n",
    "\n",
    "# restaurant test data confusion matrix\n",
    "predictions= model1.predict([X_left_test[638:], X_right_test[638:]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(restaurant_label, predictions))\n",
    "print(confusion_matrix(restaurant_label, predictions))\n",
    "print(classification_report(restaurant_label, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get train、test LSTM 64 dimension output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output=model1.get_layer('dense').output\n",
    "intermediate_model = Model(inputs=[input_layer_1, input_layer_2],outputs=layer_output)\n",
    "intermediate_prediction=intermediate_model.predict([left_text_seq, right_text_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7673, 128)\n",
      "[[0.6153577  0.         0.         ... 0.5140676  0.         0.0568014 ]\n",
      " [0.         0.         0.04505857 ... 0.         0.10509332 0.02125632]\n",
      " [0.41109017 0.         0.52117074 ... 0.2768108  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         2.6969218  1.293426  ]\n",
      " [0.         0.         0.         ... 0.         2.6723366  1.2036746 ]\n",
      " [0.         0.         0.         ... 0.         1.9964995  0.74411166]]\n"
     ]
    }
   ],
   "source": [
    "print(type(intermediate_prediction))\n",
    "print(intermediate_prediction.shape)\n",
    "print(intermediate_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把LSTM dimension 放進dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/bertenv3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "      <th>lstm_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>Anyway, the owner was fake.</td>\n",
       "      <td>owner</td>\n",
       "      <td>negative</td>\n",
       "      <td>anyway the owner</td>\n",
       "      <td>owner was fake</td>\n",
       "      <td>anyway the owner owner was fake</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.29783994, 0.0, 0.026724296, 0.053328127, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>Owner is pleasant and entertaining.</td>\n",
       "      <td>Owner</td>\n",
       "      <td>positive</td>\n",
       "      <td>owner</td>\n",
       "      <td>owner is pleasant and entertaining</td>\n",
       "      <td>owner owner is pleasant and entertaining</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.14256, 0.3379526, 0.0, 2.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>I have never in my life sent back food before,...</td>\n",
       "      <td>food</td>\n",
       "      <td>negative</td>\n",
       "      <td>i have never in my life sent back food</td>\n",
       "      <td>food before but i simply had to and the waiter...</td>\n",
       "      <td>i have never in my life sent back food food be...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9518227, 0.0, 0.0, 0.4208995, 1.1578953, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>I have never in my life sent back food before,...</td>\n",
       "      <td>waiter</td>\n",
       "      <td>negative</td>\n",
       "      <td>i have never in my life sent back food before ...</td>\n",
       "      <td>waiter argued with me over this</td>\n",
       "      <td>i have never in my life sent back food before ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.8968659, 0.0, 0.19021267, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>Although the restaurant itself is nice, I pref...</td>\n",
       "      <td>food</td>\n",
       "      <td>negative</td>\n",
       "      <td>although the restaurant itself is nice i prefe...</td>\n",
       "      <td>food</td>\n",
       "      <td>although the restaurant itself is nice i prefe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.6106661, 0.40160874, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>Creamy appetizers--taramasalata, eggplant sala...</td>\n",
       "      <td>Creamy appetizers</td>\n",
       "      <td>positive</td>\n",
       "      <td>creamy appetizers</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad...</td>\n",
       "      <td>creamy appetizers creamy appetizers  taramasal...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.5973647, 0.55685735, 0.0, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>Creamy appetizers--taramasalata, eggplant sala...</td>\n",
       "      <td>warm pitas</td>\n",
       "      <td>neutral</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad...</td>\n",
       "      <td>warm pitas</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.095603, 1.0954943, 0.0, 0.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>Creamy appetizers--taramasalata, eggplant sala...</td>\n",
       "      <td>taramasalata</td>\n",
       "      <td>positive</td>\n",
       "      <td>creamy appetizers  taramasalata</td>\n",
       "      <td>taramasalata eggplant salad and greek yogurt w...</td>\n",
       "      <td>creamy appetizers  taramasalata taramasalata e...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 3.1061869, 0.5915099, 0.0, 2.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>Creamy appetizers--taramasalata, eggplant sala...</td>\n",
       "      <td>eggplant salad</td>\n",
       "      <td>positive</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad</td>\n",
       "      <td>eggplant salad and greek yogurt with cuccumber...</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 3.0199537, 0.6858778, 0.0, 2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>Creamy appetizers--taramasalata, eggplant sala...</td>\n",
       "      <td>Greek yogurt (with cuccumber, dill, and garlic)</td>\n",
       "      <td>positive</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad...</td>\n",
       "      <td>greek yogurt with cuccumber dill and garlic ta...</td>\n",
       "      <td>creamy appetizers  taramasalata eggplant salad...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.3910232, 0.80148387, 0.0, 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "7663                        Anyway, the owner was fake.   \n",
       "7664                Owner is pleasant and entertaining.   \n",
       "7665  I have never in my life sent back food before,...   \n",
       "7666  I have never in my life sent back food before,...   \n",
       "7667  Although the restaurant itself is nice, I pref...   \n",
       "7668  Creamy appetizers--taramasalata, eggplant sala...   \n",
       "7669  Creamy appetizers--taramasalata, eggplant sala...   \n",
       "7670  Creamy appetizers--taramasalata, eggplant sala...   \n",
       "7671  Creamy appetizers--taramasalata, eggplant sala...   \n",
       "7672  Creamy appetizers--taramasalata, eggplant sala...   \n",
       "\n",
       "                                               aspect  polarity  \\\n",
       "7663                                            owner  negative   \n",
       "7664                                            Owner  positive   \n",
       "7665                                             food  negative   \n",
       "7666                                           waiter  negative   \n",
       "7667                                             food  negative   \n",
       "7668                                Creamy appetizers  positive   \n",
       "7669                                       warm pitas   neutral   \n",
       "7670                                     taramasalata  positive   \n",
       "7671                                   eggplant salad  positive   \n",
       "7672  Greek yogurt (with cuccumber, dill, and garlic)  positive   \n",
       "\n",
       "                                              left_text  \\\n",
       "7663                                   anyway the owner   \n",
       "7664                                              owner   \n",
       "7665             i have never in my life sent back food   \n",
       "7666  i have never in my life sent back food before ...   \n",
       "7667  although the restaurant itself is nice i prefe...   \n",
       "7668                                  creamy appetizers   \n",
       "7669  creamy appetizers  taramasalata eggplant salad...   \n",
       "7670                    creamy appetizers  taramasalata   \n",
       "7671     creamy appetizers  taramasalata eggplant salad   \n",
       "7672  creamy appetizers  taramasalata eggplant salad...   \n",
       "\n",
       "                                             right_text  \\\n",
       "7663                                     owner was fake   \n",
       "7664                 owner is pleasant and entertaining   \n",
       "7665  food before but i simply had to and the waiter...   \n",
       "7666                    waiter argued with me over this   \n",
       "7667                                               food   \n",
       "7668  creamy appetizers  taramasalata eggplant salad...   \n",
       "7669                                         warm pitas   \n",
       "7670  taramasalata eggplant salad and greek yogurt w...   \n",
       "7671  eggplant salad and greek yogurt with cuccumber...   \n",
       "7672  greek yogurt with cuccumber dill and garlic ta...   \n",
       "\n",
       "                                        left_right_text  label  \\\n",
       "7663                    anyway the owner owner was fake      0   \n",
       "7664           owner owner is pleasant and entertaining      2   \n",
       "7665  i have never in my life sent back food food be...      0   \n",
       "7666  i have never in my life sent back food before ...      0   \n",
       "7667  although the restaurant itself is nice i prefe...      0   \n",
       "7668  creamy appetizers creamy appetizers  taramasal...      2   \n",
       "7669  creamy appetizers  taramasalata eggplant salad...      1   \n",
       "7670  creamy appetizers  taramasalata taramasalata e...      2   \n",
       "7671  creamy appetizers  taramasalata eggplant salad...      2   \n",
       "7672  creamy appetizers  taramasalata eggplant salad...      2   \n",
       "\n",
       "                                           lstm_predict  \n",
       "7663  [0.29783994, 0.0, 0.026724296, 0.053328127, 0....  \n",
       "7664  [0.0, 0.0, 0.0, 2.14256, 0.3379526, 0.0, 2.005...  \n",
       "7665  [0.9518227, 0.0, 0.0, 0.4208995, 1.1578953, 0....  \n",
       "7666  [0.0, 0.0, 0.0, 0.8968659, 0.0, 0.19021267, 0....  \n",
       "7667  [0.0, 0.0, 0.0, 0.6106661, 0.40160874, 0.0, 0....  \n",
       "7668  [0.0, 0.0, 0.0, 2.5973647, 0.55685735, 0.0, 2....  \n",
       "7669  [0.0, 0.0, 0.0, 2.095603, 1.0954943, 0.0, 0.96...  \n",
       "7670  [0.0, 0.0, 0.0, 3.1061869, 0.5915099, 0.0, 2.3...  \n",
       "7671  [0.0, 0.0, 0.0, 3.0199537, 0.6858778, 0.0, 2.4...  \n",
       "7672  [0.0, 0.0, 0.0, 2.3910232, 0.80148387, 0.0, 1....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把LSTM predict出來的東西放進dataframe\n",
    "data['lstm_predict'] = 'N/A'\n",
    "for i in range(len(data)):\n",
    "    data['lstm_predict'][i] = intermediate_prediction[i]\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "128\n",
      "[0.         0.         0.         2.719978   1.029768   0.\n",
      " 1.9912829  0.1033069  0.         0.         2.8324864  0.\n",
      " 0.         2.8872955  0.         0.         4.0292883  0.\n",
      " 1.6299099  3.2112064  0.15822892 3.1007688  0.         2.0963035\n",
      " 0.         0.         0.         3.7101977  3.2595015  0.\n",
      " 1.8803552  0.         2.1338663  0.         3.766756   0.95988923\n",
      " 0.14947261 0.         0.         0.         0.         2.5026848\n",
      " 4.1936526  0.         1.1535277  0.         3.0017245  1.0984769\n",
      " 3.2968705  0.         1.8785983  0.         4.584175   0.\n",
      " 4.1292644  0.7932159  4.082077   2.6583815  0.         0.\n",
      " 0.         0.         0.         0.         0.         2.8812826\n",
      " 0.         1.3314581  0.         3.7014701  0.         0.\n",
      " 0.         4.067122   3.3511631  0.24262889 0.         0.68987805\n",
      " 0.         0.         3.6477823  0.85097045 0.         0.\n",
      " 2.9952211  0.05694206 3.7964575  3.4318027  0.         1.8393604\n",
      " 3.1541011  0.         0.         0.         0.         2.336868\n",
      " 3.2782125  3.6622343  0.         0.         3.9790719  0.\n",
      " 2.9244657  0.         0.         0.         0.         0.\n",
      " 0.         0.         2.6686075  0.         3.65633    1.776617\n",
      " 0.         0.         0.         2.484118   0.         0.\n",
      " 0.         0.         0.         2.509574   0.         0.\n",
      " 3.32371    1.086555  ]\n"
     ]
    }
   ],
   "source": [
    "# 稽查\n",
    "n = 504\n",
    "print(data.loc[n, 'lstm_predict'].shape)\n",
    "print(len(data.loc[n, 'lstm_predict']))\n",
    "print(data.loc[n, 'lstm_predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, TFBertForSequenceClassification, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer, to convert our text into tokens that correspond to BERT’s vocabulary.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 找出單句最多token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出最多text add aspect中最多是幾個token，不包含CLS跟SEP\n",
    "def find_max_token(pd):\n",
    "    max_token = 0\n",
    "    index = 0\n",
    "    for i in range(len(pd)):\n",
    "        text = pd.loc[i, 'text']\n",
    "        aspect = pd.loc[i, 'aspect']\n",
    "        text_aspect = text + ' ' +aspect\n",
    "        tokens_len = len(tokenizer.tokenize(text_aspect))\n",
    "        if tokens_len>max_token:\n",
    "            max_token = tokens_len\n",
    "            index = i\n",
    "    return [max_token, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料集token最多與index是: [99, 6299]\n"
     ]
    }
   ],
   "source": [
    "# 找出text add aspect中token最多的是幾個token，不包含CLS跟SEP\n",
    "max_token = find_max_token(data)\n",
    "print('資料集token最多與index是:', max_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正式把資料轉換成token(padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把句子轉變成token(CLS+text+SEP+asepct)+(padding)的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把維度固定在128維\n",
    "input_dim = 128\n",
    "def input_ids_all(pd):\n",
    "    pd['input_ids'] = 'N/A'\n",
    "    for i in range(len(pd)):\n",
    "        text = pd.loc[i, 'text']\n",
    "        aspect = pd.loc[i, 'aspect']\n",
    "        text_tokens = tokenizer.tokenize(text) # 把text轉成token\n",
    "        aspect_tokens = tokenizer.tokenize(aspect) # 把aspect轉成token\n",
    "        \n",
    "        text_input_ids = tokenizer.convert_tokens_to_ids(text_tokens) # 把text token轉成text token id\n",
    "        aspect_input_ids = tokenizer.convert_tokens_to_ids(aspect_tokens) # 把aspect token轉成aspect token id\n",
    "        \n",
    "        text_input_ids_cls = tokenizer.build_inputs_with_special_tokens(text_input_ids) # aspect token id加上CLS、SEP token id\n",
    "        input_ids = text_input_ids_cls + aspect_input_ids # 把aspect token id接在text token id 後面 (CLS+text+SEP+aspect)\n",
    "        input_ids = np.array(input_ids)\n",
    "        \n",
    "        if len(input_ids) < input_dim:\n",
    "            n = input_dim - len(input_ids)\n",
    "            input_ids = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0  補長度到512\n",
    "        \n",
    "        pd['input_ids'][i] = input_ids\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/bertenv3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "      <th>lstm_predict</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i charge it at night and skip taking the cord</td>\n",
       "      <td>cord with me because of the good battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6153577, 0.0, 0.0, 0.18314853, 1.0045241, 0...</td>\n",
       "      <td>[101, 1045, 3715, 2009, 2012, 2305, 1998, 1355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.04505857, 0.12736586, 0.0, 0.4572...</td>\n",
       "      <td>[101, 1045, 3715, 2009, 2012, 2305, 1998, 1355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center</td>\n",
       "      <td>service center does not do 1 to 1 exchange and...</td>\n",
       "      <td>the tech guy then said the service center serv...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.41109017, 0.0, 0.52117074, 0.0, 0.03945322,...</td>\n",
       "      <td>[101, 1996, 6627, 3124, 2059, 2056, 1996, 2326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>sales team which is the retail shop which i bo...</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.7332473, 0.010174245, 0.0, 0.9998...</td>\n",
       "      <td>[101, 1996, 6627, 3124, 2059, 2056, 1996, 2326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the tech guy</td>\n",
       "      <td>tech guy then said the service center does not...</td>\n",
       "      <td>the tech guy tech guy then said the service ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5331934, 0.014703929, 0.0, 0.2424311, 1.294...</td>\n",
       "      <td>[101, 1996, 6627, 3124, 2059, 2056, 1996, 2326...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          aspect  \\\n",
       "0  I charge it at night and skip taking the cord ...            cord   \n",
       "1  I charge it at night and skip taking the cord ...    battery life   \n",
       "2  The tech guy then said the service center does...  service center   \n",
       "3  The tech guy then said the service center does...    \"sales\" team   \n",
       "4  The tech guy then said the service center does...        tech guy   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0   neutral      i charge it at night and skip taking the cord   \n",
       "1  positive  i charge it at night and skip taking the cord ...   \n",
       "2  negative          the tech guy then said the service center   \n",
       "3  negative  the tech guy then said the service center does...   \n",
       "4   neutral                                       the tech guy   \n",
       "\n",
       "                                          right_text  \\\n",
       "0      cord with me because of the good battery life   \n",
       "1                                       battery life   \n",
       "2  service center does not do 1 to 1 exchange and...   \n",
       "3  sales team which is the retail shop which i bo...   \n",
       "4  tech guy then said the service center does not...   \n",
       "\n",
       "                                     left_right_text  label  \\\n",
       "0  i charge it at night and skip taking the cord ...      1   \n",
       "1  i charge it at night and skip taking the cord ...      2   \n",
       "2  the tech guy then said the service center serv...      0   \n",
       "3  the tech guy then said the service center does...      0   \n",
       "4  the tech guy tech guy then said the service ce...      1   \n",
       "\n",
       "                                        lstm_predict  \\\n",
       "0  [0.6153577, 0.0, 0.0, 0.18314853, 1.0045241, 0...   \n",
       "1  [0.0, 0.0, 0.04505857, 0.12736586, 0.0, 0.4572...   \n",
       "2  [0.41109017, 0.0, 0.52117074, 0.0, 0.03945322,...   \n",
       "3  [0.0, 0.0, 0.7332473, 0.010174245, 0.0, 0.9998...   \n",
       "4  [0.5331934, 0.014703929, 0.0, 0.2424311, 1.294...   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [101, 1045, 3715, 2009, 2012, 2305, 1998, 1355...  \n",
       "1  [101, 1045, 3715, 2009, 2012, 2305, 1998, 1355...  \n",
       "2  [101, 1996, 6627, 3124, 2059, 2056, 1996, 2326...  \n",
       "3  [101, 1996, 6627, 3124, 2059, 2056, 1996, 2326...  \n",
       "4  [101, 1996, 6627, 3124, 2059, 2056, 1996, 2326...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將text轉成token，後面加上aspect token存進dataframe\n",
    "data = input_ids_all(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Like New condition of the iMac MC309LL/A on Amazon is at $900+ level only, and it is a Quad-Core 2.5 GHz CPU (similar to the $799 Mini), with Radeon HD 6750M 512MB graphic card (this mini is integrated Intel 4000 card), and it even comes with wireless Apple Keyboard and Mouse, all put together in neat and nice package.\n",
      "Radeon HD 6750M 512MB graphic card\n",
      "[  101  1996  2066  2047  4650  1997  1996 10047  6305 11338 14142  2683\n",
      "  3363  1013  1037  2006  9733  2003  2012  1002  7706  1009  2504  2069\n",
      "  1010  1998  2009  2003  1037 17718  1011  4563  1016  1012  1019 29066\n",
      " 17368  1006  2714  2000  1996  1002  6535  2683  7163  1007  1010  2007\n",
      " 10958  3207  2239 10751  6163 12376  2213 24406 14905  8425  4003  1006\n",
      "  2023  7163  2003  6377 13420 20143  4003  1007  1010  1998  2009  2130\n",
      "  3310  2007  9949  6207  9019  1998  8000  1010  2035  2404  2362  1999\n",
      " 15708  1998  3835  7427  1012   102 10958  3207  2239 10751  6163 12376\n",
      "  2213 24406 14905  8425  4003     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# 稽查\n",
    "n = 6299\n",
    "print(data.loc[n, 'text'])\n",
    "print(data.loc[n, 'aspect'])\n",
    "print(data.loc[n, 'input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7673, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  101,  1045,  3715, ...,     0,     0,     0],\n",
       "       [  101,  1045,  3715, ...,     0,     0,     0],\n",
       "       [  101,  1996,  6627, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0],\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0],\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把data的input_ids提出存進list\n",
    "input_ids = list()\n",
    "for i in range(len(data)):\n",
    "    np_id = data.loc[i, 'input_ids']\n",
    "    input_ids.append(np_id)\n",
    "input_ids = np.array(input_ids)\n",
    "print(input_ids.shape)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7673, 128)\n",
      "[[0.6153577  0.         0.         ... 0.5140676  0.         0.0568014 ]\n",
      " [0.         0.         0.04505857 ... 0.         0.10509332 0.02125632]\n",
      " [0.41109017 0.         0.52117074 ... 0.2768108  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         2.6969218  1.293426  ]\n",
      " [0.         0.         0.         ... 0.         2.6723366  1.2036746 ]\n",
      " [0.         0.         0.         ... 0.         1.9964995  0.74411166]]\n"
     ]
    }
   ],
   "source": [
    "# 把data的lstm_predcit提出存進list\n",
    "lstm_predict = list()\n",
    "for i in range(len(data)):\n",
    "    np_lstm = data.loc[i, 'lstm_predict']\n",
    "    lstm_predict.append(np_lstm)\n",
    "lstm_predict = np.array(lstm_predict)\n",
    "print(type(lstm_predict))\n",
    "print(lstm_predict.shape)\n",
    "print(lstm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把data label變成numpy\n",
    "label = data['label'].to_numpy()\n",
    "print(len(label))\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切train、test資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915, 128)\n",
      "[[ 101 1045 3715 ...    0    0    0]\n",
      " [ 101 1045 3715 ...    0    0    0]\n",
      " [ 101 1996 6627 ...    0    0    0]\n",
      " ...\n",
      " [ 101 2169 2795 ...    0    0    0]\n",
      " [ 101 2169 2795 ...    0    0    0]\n",
      " [ 101 2169 2795 ...    0    0    0]]\n",
      "\n",
      "(1758, 128)\n",
      "[[  101  9573  2051 ...     0     0     0]\n",
      " [  101  6627  2490 ...     0     0     0]\n",
      " [  101  2275  2039 ...     0     0     0]\n",
      " ...\n",
      " [  101 24519 10439 ...     0     0     0]\n",
      " [  101 24519 10439 ...     0     0     0]\n",
      " [  101 24519 10439 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# X\n",
    "train_input_ids = input_ids[:5915]\n",
    "test_input_ids = input_ids[5915:]\n",
    "print(train_input_ids.shape)\n",
    "print(train_input_ids)\n",
    "print()\n",
    "print(test_input_ids.shape)\n",
    "print(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915, 128)\n",
      "(1758, 128)\n"
     ]
    }
   ],
   "source": [
    "# lstm predict\n",
    "train_lstm_predict = lstm_predict[:5915]\n",
    "test_lstm_predict = lstm_predict[5915:]\n",
    "print(train_lstm_predict.shape)\n",
    "print(test_lstm_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915,)\n",
      "[1 2 0 ... 1 1 1]\n",
      "\n",
      "(1758,)\n",
      "[2 0 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Y\n",
    "train_label = label[:5915]\n",
    "test_label = label[5915:]\n",
    "print(train_label.shape)\n",
    "print(train_label)\n",
    "print()\n",
    "print(test_label.shape)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "neutral 1 1\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n"
     ]
    }
   ],
   "source": [
    "# 檢查polarity跟label有沒有不一樣\n",
    "print('test_data')\n",
    "for i in range(15):\n",
    "    print(test_data.loc[i, 'polarity'], data.loc[5915+i, 'label'], test_label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model_5 (TFBertModel ((None, 128, 768), (None, 109482240 \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 128, 768)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 98304)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               12583040  \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 122,065,667\n",
      "Trainable params: 122,065,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer= Input(shape = (128,), dtype='int64')\n",
    "# lstm_input_layer = Input(shape = (128,), dtype='float32')\n",
    "# print(type(input_layer))\n",
    "# print(type(lstm_input_layer))\n",
    "bert = TFBertModel.from_pretrained('bert-base-uncased')(input_layer)\n",
    "bert = bert[0]\n",
    "dropout = Dropout(0.1)(bert)\n",
    "flat = Flatten()(dropout)\n",
    "dense_1 = Dense(units=128)(flat)\n",
    "# print(type(dense_1))\n",
    "\n",
    "# merge = concatenate([dense_1, lstm_input_layer])\n",
    "classifier = Dense(units=3)(dense_1) # 分3類\n",
    "model = Model(inputs=input_layer, outputs=classifier)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \n",
    "# # num_labels=3 分3類\n",
    "# model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "# model.summary()\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1758 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "5915/5915 [==============================] - 133s 22ms/sample - loss: 0.8958 - accuracy: 0.6727 - val_loss: 0.5370 - val_accuracy: 0.7964\n",
      "Epoch 2/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.5872 - accuracy: 0.7905 - val_loss: 0.4978 - val_accuracy: 0.7992\n",
      "Epoch 3/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.3698 - accuracy: 0.8697 - val_loss: 0.5705 - val_accuracy: 0.7833\n",
      "Epoch 4/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.2965 - accuracy: 0.9018 - val_loss: 0.6815 - val_accuracy: 0.8015\n",
      "Epoch 5/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.1941 - accuracy: 0.9373 - val_loss: 0.7970 - val_accuracy: 0.8009\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_input_ids, train_label, \n",
    "                      batch_size=4, epochs=5, \n",
    "                      validation_data=(test_input_ids, test_label), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get train、test BERT 128 dimension output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output=model.get_layer('dense_19').output\n",
    "intermediate_model = Model(inputs=input_layer,outputs=layer_output)\n",
    "intermediate_prediction=intermediate_model.predict(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7673, 128)\n",
      "[[ 0.68260163 -0.4627373   0.16000712 ... -1.1491781   0.05248769\n",
      "  -0.263877  ]\n",
      " [-0.46024865  0.53016216 -0.36681974 ...  0.2633916   1.4116355\n",
      "   0.66534805]\n",
      " [ 0.46934295 -0.55190027  0.18329841 ... -0.6966846   0.54983187\n",
      "   0.01628807]\n",
      " ...\n",
      " [-0.28497407  0.33559287 -0.6235323  ...  1.285512    1.2011584\n",
      "   0.42756274]\n",
      " [-0.223069   -0.2866009  -0.2205159  ...  1.6681943   0.9824842\n",
      "   0.05190899]\n",
      " [-0.44749096  0.9202354  -0.51188177 ...  1.4626744   1.6955111\n",
      "   0.9330041 ]]\n"
     ]
    }
   ],
   "source": [
    "bert_feature = intermediate_prediction\n",
    "print(type(bert_feature))\n",
    "print(bert_feature.shape)\n",
    "print(bert_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915, 128)\n",
      "(1758, 128)\n"
     ]
    }
   ],
   "source": [
    "train_bert_predict = bert_feature[:5915]\n",
    "test_bert_predict = bert_feature[5915:]\n",
    "print(train_bert_predict.shape)\n",
    "print(test_bert_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915, 128)\n",
      "(1758, 128)\n"
     ]
    }
   ],
   "source": [
    "print(train_lstm_predict.shape)\n",
    "print(test_lstm_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把兩個訓練好的模型輸出丟到dense訊練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256)          0           input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            771         concatenate_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm_input_layer = Input(shape = (128,), dtype='float32')\n",
    "bert_input_layer = Input(shape = (128,), dtype='float32')\n",
    "merge = concatenate([lstm_input_layer, bert_input_layer])\n",
    "classifier = Dense(units=3)(merge) # 分3類\n",
    "modelfix = Model(inputs=[lstm_input_layer, bert_input_layer], outputs=classifier)\n",
    "print(modelfix.summary())\n",
    "# adam = Adam(lr=1e-2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "modelfix.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1758 samples\n",
      "Epoch 1/30\n",
      "5915/5915 [==============================] - 0s 44us/sample - loss: 0.1024 - accuracy: 0.9645 - val_loss: 0.8147 - val_accuracy: 0.8129\n",
      "Epoch 2/30\n",
      "5915/5915 [==============================] - 0s 18us/sample - loss: 0.0593 - accuracy: 0.9814 - val_loss: 0.7629 - val_accuracy: 0.8191\n",
      "Epoch 3/30\n",
      "5915/5915 [==============================] - 0s 20us/sample - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.7661 - val_accuracy: 0.8100\n",
      "Epoch 4/30\n",
      "5915/5915 [==============================] - 0s 20us/sample - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.7542 - val_accuracy: 0.8174\n",
      "Epoch 5/30\n",
      "5915/5915 [==============================] - 0s 20us/sample - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.7190 - val_accuracy: 0.8191\n",
      "Epoch 6/30\n",
      "5915/5915 [==============================] - 0s 20us/sample - loss: 0.0517 - accuracy: 0.9836 - val_loss: 0.8733 - val_accuracy: 0.8049\n",
      "Epoch 7/30\n",
      "5915/5915 [==============================] - 0s 19us/sample - loss: 0.0539 - accuracy: 0.9831 - val_loss: 1.0335 - val_accuracy: 0.8094\n",
      "Epoch 8/30\n",
      "5915/5915 [==============================] - 0s 18us/sample - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.9691 - val_accuracy: 0.8055\n",
      "Epoch 9/30\n",
      "5915/5915 [==============================] - 0s 19us/sample - loss: 0.0504 - accuracy: 0.9833 - val_loss: 0.8718 - val_accuracy: 0.8111\n",
      "Epoch 10/30\n",
      "5915/5915 [==============================] - 0s 19us/sample - loss: 0.0477 - accuracy: 0.9826 - val_loss: 0.7428 - val_accuracy: 0.8129\n",
      "Epoch 11/30\n",
      "5915/5915 [==============================] - 0s 19us/sample - loss: 0.0502 - accuracy: 0.9841 - val_loss: 0.7723 - val_accuracy: 0.8146\n",
      "Epoch 12/30\n",
      "3520/5915 [================>.............] - ETA: 0s - loss: 0.0443 - accuracy: 0.9861Restoring model weights from the end of the best epoch.\n",
      "5915/5915 [==============================] - 0s 19us/sample - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.9253 - val_accuracy: 0.8129\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelfix_fit = modelfix.fit([train_lstm_predict, train_bert_predict],Y_train, batch_size=64,epochs=30,\n",
    "                      validation_data=([test_lstm_predict, test_bert_predict],Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8191126279863481\n",
      "[[265  26  33]\n",
      " [ 86 183  96]\n",
      " [ 42  35 992]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74       324\n",
      "           1       0.75      0.50      0.60       365\n",
      "           2       0.88      0.93      0.91      1069\n",
      "\n",
      "    accuracy                           0.82      1758\n",
      "   macro avg       0.77      0.75      0.75      1758\n",
      "weighted avg       0.82      0.82      0.81      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test data confusion\n",
    "predictions_test= modelfix.predict([test_lstm_predict,test_bert_predict]) # 輸出的是n*5的編碼值array\n",
    "predictions_test = np.argmax(predictions_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(test_label, predictions_test))\n",
    "print(confusion_matrix(test_label, predictions_test))\n",
    "print(classification_report(test_label, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7664576802507836\n",
      "[[106  13   9]\n",
      " [ 52  81  36]\n",
      " [ 19  20 302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       128\n",
      "           1       0.71      0.48      0.57       169\n",
      "           2       0.87      0.89      0.88       341\n",
      "\n",
      "    accuracy                           0.77       638\n",
      "   macro avg       0.73      0.73      0.72       638\n",
      "weighted avg       0.77      0.77      0.76       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laptop_test confusion\n",
    "laptop_test_lstm_predict = test_lstm_predict[:638]\n",
    "laptop_test_bert_predict = test_bert_predict[:638]\n",
    "laptop_test_label = test_label[:638]\n",
    "predictions_lap_test = modelfix.predict([laptop_test_lstm_predict, laptop_test_bert_predict])\n",
    "predictions_lap_test = np.argmax(predictions_lap_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(laptop_test_label, predictions_lap_test))\n",
    "print(confusion_matrix(laptop_test_label, predictions_lap_test))\n",
    "print(classification_report(laptop_test_label, predictions_lap_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491071428571428\n",
      "[[159  13  24]\n",
      " [ 34 102  60]\n",
      " [ 23  15 690]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       196\n",
      "           1       0.78      0.52      0.63       196\n",
      "           2       0.89      0.95      0.92       728\n",
      "\n",
      "    accuracy                           0.85      1120\n",
      "   macro avg       0.80      0.76      0.77      1120\n",
      "weighted avg       0.85      0.85      0.84      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laptop_test confusion\n",
    "restaurant_test_lstm_predict = test_lstm_predict[638:]\n",
    "restaurant_test_bert_predict = test_bert_predict[638:]\n",
    "restaurant_test_label = test_label[638:]\n",
    "predictions_res_test = modelfix.predict([restaurant_test_lstm_predict, restaurant_test_bert_predict])\n",
    "predictions_res_test = np.argmax(predictions_res_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(restaurant_test_label, predictions_res_test))\n",
    "print(confusion_matrix(restaurant_test_label, predictions_res_test))\n",
    "print(classification_report(restaurant_test_label, predictions_res_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
