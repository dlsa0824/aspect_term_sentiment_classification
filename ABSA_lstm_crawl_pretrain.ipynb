{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用crawl-300d的pretrain model來做 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對處理好的laptop、restaurant的train、test資料作前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把dataframe裡的text切成text左邊跟右邊並做一些處理的function\n",
    "def split_text(df):\n",
    "    df['left_text'] = 'N/A'\n",
    "    df['right_text'] = 'N/A'\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        text = df.loc[i, 'text']\n",
    "        aspect = df.loc[i, 'aspect']\n",
    "        text_split = text.split(aspect) # 根據aspect切割text左右邊\n",
    "        \n",
    "        left_text = text_split[0]+aspect\n",
    "        right_text = aspect+text_split[1]\n",
    "        left_text = left_text.lower() # 把字串變成小寫\n",
    "        right_text = right_text.lower()\n",
    "        left_text = re.sub('-', ' ', left_text)\n",
    "        right_text = re.sub('-', ' ', right_text)\n",
    "        left_text = re.sub('[.,!\"()#%&/:?~]', '', left_text) # 把字串中的一些符號刪除\n",
    "        right_text = re.sub('[.,!\"()#%&/:?~]', '', right_text)\n",
    "        \n",
    "        df.loc[i,'left_text'] = left_text\n",
    "        df.loc[i,'right_text'] = right_text\n",
    "        df.loc[i, 'left_right_text'] = left_text +' '+ right_text # 用來文字encoding\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7673/7673 [00:02<00:00, 2763.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集: 5915\n",
      "測試資料集: 1758\n",
      "所有資料集: 7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i charge it at night and skip taking the cord</td>\n",
       "      <td>cord with me because of the good battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center</td>\n",
       "      <td>service center does not do 1 to 1 exchange and...</td>\n",
       "      <td>the tech guy then said the service center serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>sales team which is the retail shop which i bo...</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the tech guy</td>\n",
       "      <td>tech guy then said the service center does not...</td>\n",
       "      <td>the tech guy tech guy then said the service ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>quality</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality</td>\n",
       "      <td>quality has a killer gui is extremely stable i...</td>\n",
       "      <td>it is of high quality quality has a killer gui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>GUI</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui</td>\n",
       "      <td>gui is extremely stable is highly expandable i...</td>\n",
       "      <td>it is of high quality has a killer gui gui is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>applications</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>applications is easy to use and is absolutely ...</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>use and is absolutely gorgeous</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Easy to start up and does not overheat as much...</td>\n",
       "      <td>start up</td>\n",
       "      <td>positive</td>\n",
       "      <td>easy to start up</td>\n",
       "      <td>start up and does not overheat as much as othe...</td>\n",
       "      <td>easy to start up start up and does not overhea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          aspect  \\\n",
       "0  I charge it at night and skip taking the cord ...            cord   \n",
       "1  I charge it at night and skip taking the cord ...    battery life   \n",
       "2  The tech guy then said the service center does...  service center   \n",
       "3  The tech guy then said the service center does...    \"sales\" team   \n",
       "4  The tech guy then said the service center does...        tech guy   \n",
       "5  it is of high quality, has a killer GUI, is ex...         quality   \n",
       "6  it is of high quality, has a killer GUI, is ex...             GUI   \n",
       "7  it is of high quality, has a killer GUI, is ex...    applications   \n",
       "8  it is of high quality, has a killer GUI, is ex...             use   \n",
       "9  Easy to start up and does not overheat as much...        start up   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0   neutral      i charge it at night and skip taking the cord   \n",
       "1  positive  i charge it at night and skip taking the cord ...   \n",
       "2  negative          the tech guy then said the service center   \n",
       "3  negative  the tech guy then said the service center does...   \n",
       "4   neutral                                       the tech guy   \n",
       "5  positive                              it is of high quality   \n",
       "6  positive             it is of high quality has a killer gui   \n",
       "7  positive  it is of high quality has a killer gui is extr...   \n",
       "8  positive  it is of high quality has a killer gui is extr...   \n",
       "9  positive                                   easy to start up   \n",
       "\n",
       "                                          right_text  \\\n",
       "0      cord with me because of the good battery life   \n",
       "1                                       battery life   \n",
       "2  service center does not do 1 to 1 exchange and...   \n",
       "3  sales team which is the retail shop which i bo...   \n",
       "4  tech guy then said the service center does not...   \n",
       "5  quality has a killer gui is extremely stable i...   \n",
       "6  gui is extremely stable is highly expandable i...   \n",
       "7  applications is easy to use and is absolutely ...   \n",
       "8                     use and is absolutely gorgeous   \n",
       "9  start up and does not overheat as much as othe...   \n",
       "\n",
       "                                     left_right_text  \n",
       "0  i charge it at night and skip taking the cord ...  \n",
       "1  i charge it at night and skip taking the cord ...  \n",
       "2  the tech guy then said the service center serv...  \n",
       "3  the tech guy then said the service center does...  \n",
       "4  the tech guy tech guy then said the service ce...  \n",
       "5  it is of high quality quality has a killer gui...  \n",
       "6  it is of high quality has a killer gui gui is ...  \n",
       "7  it is of high quality has a killer gui is extr...  \n",
       "8  it is of high quality has a killer gui is extr...  \n",
       "9  easy to start up start up and does not overhea...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_train = pd.read_csv('dataset/laptop_train_processed.csv', encoding='utf-8')\n",
    "restaurant_train = pd.read_csv('dataset/restaurant_train_processed.csv', encoding='utf-8')\n",
    "laptop_test = pd.read_csv('dataset/laptop_test_processed.csv', encoding='utf-8')\n",
    "restaurant_test = pd.read_csv('dataset/restaurant_test_processed.csv', encoding='utf-8')\n",
    "\n",
    "# 把train的資料串在一起\n",
    "train_data = laptop_train.append(restaurant_train)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "#把test的資料串在一起\n",
    "test_data = laptop_test.append(restaurant_test)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "#把train、test資料串在一起\n",
    "data = train_data.append(test_data)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# data切割text\n",
    "data = split_text(data)\n",
    "\n",
    "print('訓練資料集:', len(train_data))\n",
    "print('測試資料集:', len(test_data))\n",
    "print('所有資料集:', len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.\n",
      "\n",
      "the tech guy then said the service center does not do 1 to 1 exchange and i have to direct my concern to the sales team\n",
      "\n",
      "sales team which is the retail shop which i bought my netbook from\n",
      "\n",
      "the tech guy then said the service center does not do 1 to 1 exchange and i have to direct my concern to the sales team sales team which is the retail shop which i bought my netbook from\n"
     ]
    }
   ],
   "source": [
    "# print一個出來看看\n",
    "n = 3\n",
    "print(data.loc[n, 'text'])\n",
    "print()\n",
    "print(data.loc[n, 'left_text'])\n",
    "print()\n",
    "print(data.loc[n, 'right_text'])\n",
    "print()\n",
    "print(data.loc[n, 'left_right_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i charge it at night and skip taking the cord</td>\n",
       "      <td>cord with me because of the good battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center</td>\n",
       "      <td>service center does not do 1 to 1 exchange and...</td>\n",
       "      <td>the tech guy then said the service center serv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>sales team which is the retail shop which i bo...</td>\n",
       "      <td>the tech guy then said the service center does...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the tech guy</td>\n",
       "      <td>tech guy then said the service center does not...</td>\n",
       "      <td>the tech guy tech guy then said the service ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>quality</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality</td>\n",
       "      <td>quality has a killer gui is extremely stable i...</td>\n",
       "      <td>it is of high quality quality has a killer gui...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>GUI</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui</td>\n",
       "      <td>gui is extremely stable is highly expandable i...</td>\n",
       "      <td>it is of high quality has a killer gui gui is ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>applications</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>applications is easy to use and is absolutely ...</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it is of high quality, has a killer GUI, is ex...</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>use and is absolutely gorgeous</td>\n",
       "      <td>it is of high quality has a killer gui is extr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Easy to start up and does not overheat as much...</td>\n",
       "      <td>start up</td>\n",
       "      <td>positive</td>\n",
       "      <td>easy to start up</td>\n",
       "      <td>start up and does not overheat as much as othe...</td>\n",
       "      <td>easy to start up start up and does not overhea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          aspect  \\\n",
       "0  I charge it at night and skip taking the cord ...            cord   \n",
       "1  I charge it at night and skip taking the cord ...    battery life   \n",
       "2  The tech guy then said the service center does...  service center   \n",
       "3  The tech guy then said the service center does...    \"sales\" team   \n",
       "4  The tech guy then said the service center does...        tech guy   \n",
       "5  it is of high quality, has a killer GUI, is ex...         quality   \n",
       "6  it is of high quality, has a killer GUI, is ex...             GUI   \n",
       "7  it is of high quality, has a killer GUI, is ex...    applications   \n",
       "8  it is of high quality, has a killer GUI, is ex...             use   \n",
       "9  Easy to start up and does not overheat as much...        start up   \n",
       "\n",
       "   polarity                                          left_text  \\\n",
       "0   neutral      i charge it at night and skip taking the cord   \n",
       "1  positive  i charge it at night and skip taking the cord ...   \n",
       "2  negative          the tech guy then said the service center   \n",
       "3  negative  the tech guy then said the service center does...   \n",
       "4   neutral                                       the tech guy   \n",
       "5  positive                              it is of high quality   \n",
       "6  positive             it is of high quality has a killer gui   \n",
       "7  positive  it is of high quality has a killer gui is extr...   \n",
       "8  positive  it is of high quality has a killer gui is extr...   \n",
       "9  positive                                   easy to start up   \n",
       "\n",
       "                                          right_text  \\\n",
       "0      cord with me because of the good battery life   \n",
       "1                                       battery life   \n",
       "2  service center does not do 1 to 1 exchange and...   \n",
       "3  sales team which is the retail shop which i bo...   \n",
       "4  tech guy then said the service center does not...   \n",
       "5  quality has a killer gui is extremely stable i...   \n",
       "6  gui is extremely stable is highly expandable i...   \n",
       "7  applications is easy to use and is absolutely ...   \n",
       "8                     use and is absolutely gorgeous   \n",
       "9  start up and does not overheat as much as othe...   \n",
       "\n",
       "                                     left_right_text  label  \n",
       "0  i charge it at night and skip taking the cord ...      1  \n",
       "1  i charge it at night and skip taking the cord ...      2  \n",
       "2  the tech guy then said the service center serv...      0  \n",
       "3  the tech guy then said the service center does...      0  \n",
       "4  the tech guy tech guy then said the service ce...      1  \n",
       "5  it is of high quality quality has a killer gui...      2  \n",
       "6  it is of high quality has a killer gui gui is ...      2  \n",
       "7  it is of high quality has a killer gui is extr...      2  \n",
       "8  it is of high quality has a killer gui is extr...      2  \n",
       "9  easy to start up start up and does not overhea...      2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把文字Label變成數字label\n",
    "data.loc[data['polarity'] == 'positive', 'label'] = 2\n",
    "data.loc[data['polarity'] == 'neutral', 'label'] = 1\n",
    "data.loc[data['polarity'] == 'negative', 'label'] = 0\n",
    "data['label'] = data['label'].astype(int)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_text與right_text最多的字數: 72\n"
     ]
    }
   ],
   "source": [
    "#找出left_text跟right_text裡面最多是多少字\n",
    "max_count = 0\n",
    "for i in range(len(data)):\n",
    "    left_text_word_count = len(data.loc[i,'left_text'].split())\n",
    "    right_text_word_count = len(data.loc[i,'right_text'].split())\n",
    "    big_count = max(left_text_word_count, right_text_word_count)\n",
    "    if big_count>max_count:\n",
    "        max_count = big_count\n",
    "print('left_text與right_text最多的字數:', max_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對文字做encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 7000 # 最大的字數\n",
    "max_seq_length = 80 # 句子最長長度\n",
    "embedding_dim = 300 # 每個字維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6557 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# 把字變成token\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(data['left_right_text'].to_numpy())\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "# word_index就是根據left_right_text內容彙整出來的切字跟代表那個字的token number (每個字的dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : 1\n",
      "and : 2\n",
      "a : 3\n",
      "to : 4\n",
      "is : 5\n",
      "i : 6\n",
      "of : 7\n",
      "for : 8\n",
      "food : 9\n",
      "it : 10\n"
     ]
    }
   ],
   "source": [
    "# 檢查word_index(dictionary)裡面的東西，前面是字，後面是token\n",
    "for x in list(word_index)[0:10]:\n",
    "    print (x, ':', word_index[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i charge it at night and skip taking the cord\n",
      "cord with me because of the good battery life\n",
      "[6, 353, 10, 31, 267, 2, 1779, 899, 1, 1146]\n",
      "[1146, 12, 56, 94, 7, 1, 26, 49, 90]\n",
      "<class 'list'>\n",
      "right text 倒過來\n",
      "[6, 353, 10, 31, 267, 2, 1779, 899, 1, 1146]\n",
      "[90, 49, 26, 1, 7, 94, 56, 12, 1146]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 檢查其中一項字串的token\n",
    "n = 0 # index number\n",
    "left_text = data['left_text'].to_numpy() # 轉成向量\n",
    "right_text = data['right_text'].to_numpy()\n",
    "left_text_seq = tokenizer.texts_to_sequences(left_text)\n",
    "right_text_seq = tokenizer.texts_to_sequences(right_text)\n",
    "print(data.loc[n, 'left_text'])\n",
    "print(data.loc[n, 'right_text'])\n",
    "print(left_text_seq[n])\n",
    "print(right_text_seq[n])\n",
    "print(type(right_text_seq))\n",
    "# 把右邊的字串token倒過來，因為要從後面讀到前面\n",
    "print('right text 倒過來')\n",
    "for i in range(len(right_text_seq)):\n",
    "    right_text_seq[i] = right_text_seq[i][::-1]\n",
    "print(left_text_seq[n])\n",
    "print(right_text_seq[n])\n",
    "print(type(right_text_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6  353   10   31  267    2 1779  899    1 1146    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "[  90   49   26    1    7   94   56   12 1146    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# token sequence 後面補0的方法\n",
    "def text_seq_padding(text_seq):\n",
    "    if len(text_seq) < max_seq_length:\n",
    "        n = max_seq_length - len(text_seq)\n",
    "        text_seq = np.pad(text_seq, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0\n",
    "    return text_seq\n",
    "# 把每個left_text_seq，right_text_seq padding到同樣的長度 (後面補0)\n",
    "left_text_seq = [text_seq_padding(i) for i in left_text_seq] # 必須要 [ ] 輸出是list\n",
    "left_text_seq = np.array(left_text_seq)\n",
    "\n",
    "right_text_seq = [text_seq_padding(i) for i in right_text_seq]\n",
    "right_text_seq = np.array(right_text_seq)\n",
    "\n",
    "n = 0 # index number\n",
    "print(left_text_seq[n])\n",
    "print(right_text_seq[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用預先處理的詞向量 (crawl 300 dim)\n",
    "#### https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 載入詞向量\n",
    "# embeddings_index = {}\n",
    "# file = open('dataset/crawl-300d-2M.vec', 'r', encoding='utf-8')\n",
    "# for line in tqdm(file):\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# file.close()\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNK = embeddings_index['UNK'] # unknown token\n",
    "# print(UNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 根據得到的字典生成word_index裡每個字的詞向量\n",
    "# real_word = 0\n",
    "# embedding_matrix = np.zeros((len(word_index)+1, embedding_dim))       #預設一個全部都是0的matrix，總共有每一個unique token的數量\n",
    "# for word, i in word_index.items():                                    #dict的index從1開始，所以np.zeros()數量要 +1\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector         #將找到的embedding vector丟到他位置的matrix, 如果找不到一樣維持0\n",
    "#         real_word = real_word + 1 # 看真正有找到的詞有幾個\n",
    "#     else:\n",
    "#         embedding_matrix[i] = UNK\n",
    "# print(embedding_matrix.shape)\n",
    "# print(embedding_matrix)\n",
    "# print('總共不重複的字數:', len(word_index))\n",
    "# print('在字典裡找到的字數:', real_word)\n",
    "# # embedding_matrix就是把word_index裡面的每個字所代表word embedding對應變成一個matrix (每個字的word embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6558, 300)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.0231      0.017       0.0157     ...  0.0744     -0.1118\n",
      "   0.0963    ]\n",
      " [-0.1081      0.0191      0.0354     ...  0.1104      0.0475\n",
      "  -0.0599    ]\n",
      " ...\n",
      " [ 0.16580001 -0.0169     -0.4138     ...  0.0933     -0.1168\n",
      "  -0.1777    ]\n",
      " [-0.1179      0.0726     -0.005      ...  0.2079      0.0322\n",
      "  -0.26879999]\n",
      " [ 0.24439999  0.1206      0.1123     ... -0.147      -0.0186\n",
      "  -0.3204    ]]\n"
     ]
    }
   ],
   "source": [
    "# 把embedding_matrix load 近來\n",
    "embedding_matrix = np.load('dataset/embedding_matrix.npy')\n",
    "print(type(embedding_matrix))\n",
    "print(embedding_matrix.shape)\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認資料、並切割成train、test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i charge it at night and skip taking the cord</td>\n",
       "      <td>cord with me because of the good battery life</td>\n",
       "      <td>i charge it at night and skip taking the cord ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text aspect polarity  \\\n",
       "0  I charge it at night and skip taking the cord ...   cord  neutral   \n",
       "\n",
       "                                       left_text  \\\n",
       "0  i charge it at night and skip taking the cord   \n",
       "\n",
       "                                      right_text  \\\n",
       "0  cord with me because of the good battery life   \n",
       "\n",
       "                                     left_right_text  label  \n",
       "0  i charge it at night and skip taking the cord ...      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>positive</td>\n",
       "      <td>boot time</td>\n",
       "      <td>boot time is super fast around anywhere from 3...</td>\n",
       "      <td>boot time boot time is super fast around anywh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     aspect  polarity  \\\n",
       "5915  Boot time is super fast, around anywhere from ...  Boot time  positive   \n",
       "\n",
       "      left_text                                         right_text  \\\n",
       "5915  boot time  boot time is super fast around anywhere from 3...   \n",
       "\n",
       "                                        left_right_text  label  \n",
       "5915  boot time boot time is super fast around anywh...      2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[[5915]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>left_text</th>\n",
       "      <th>right_text</th>\n",
       "      <th>left_right_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>The bread is top notch as well.</td>\n",
       "      <td>bread</td>\n",
       "      <td>positive</td>\n",
       "      <td>the bread</td>\n",
       "      <td>bread is top notch as well</td>\n",
       "      <td>the bread bread is top notch as well</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text aspect  polarity  left_text  \\\n",
       "6553  The bread is top notch as well.  bread  positive  the bread   \n",
       "\n",
       "                      right_text                       left_right_text  label  \n",
       "6553  bread is top notch as well  the bread bread is top notch as well      2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[[6553]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boot time\n",
      "boot time is super fast around anywhere from 35 seconds to 1 minute\n",
      "[500  98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "[1318  434    4 1017 2018   44  844  261  139  532    5   98  500    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "the bread\n",
      "bread is top notch as well\n",
      "[  1 309   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "[  71   30 1061  359    5  309    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 稽查dataframe、token sequence裡面laptop_test、restaurant_test資料是否一致\n",
    "# laptop_test第一筆在5915；restaurant_test第一筆在6553\n",
    "print(data.loc[5915, 'left_text'])\n",
    "print(data.loc[5915, 'right_text'])\n",
    "print(left_text_seq[5915])\n",
    "print(right_text_seq[5915])\n",
    "print()\n",
    "print(data.loc[6553, 'left_text'])\n",
    "print(data.loc[6553, 'right_text'])\n",
    "print(left_text_seq[6553])\n",
    "print(right_text_seq[6553])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (7673, 3)\n",
      "1 [0 1 0]\n",
      "2 [0 0 1]\n",
      "0 [1 0 0]\n",
      "0 [1 0 0]\n",
      "1 [0 1 0]\n",
      "2 [0 0 1]\n",
      "2 [0 0 1]\n",
      "2 [0 0 1]\n",
      "2 [0 0 1]\n",
      "2 [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 把label轉成2維矩陣\n",
    "Y = pd.get_dummies(data['label']).to_numpy() # label轉乘2維矩陣   # keras不吃1維label\n",
    "print('Shape of Y:', Y.shape)\n",
    "for i in range(10):\n",
    "    print(data.loc[i, 'label'], Y[i])\n",
    "#[1 0 0] = negative\n",
    "#[0 1 0] = neutral\n",
    "#[0 0 1] = positve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5915 5915 5915\n",
      "1758 1758 1758\n"
     ]
    }
   ],
   "source": [
    "#把資料切割成train、test\n",
    "X_left_train = left_text_seq[:5915]\n",
    "X_right_train = right_text_seq[:5915]\n",
    "Y_train = Y[:5915]\n",
    "X_left_test = left_text_seq[5915:]\n",
    "X_right_test = right_text_seq[5915:]\n",
    "Y_test = Y[5915:]\n",
    "print(len(X_left_train), len(X_right_train), len(Y_train))\n",
    "print(len(X_left_test), len(X_right_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop_test           restaurant_test\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "negative 0 [1 0 0]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "negative 0 [1 0 0]    positive 2 [0 0 1]\n",
      "negative 0 [1 0 0]    positive 2 [0 0 1]\n",
      "negative 0 [1 0 0]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "negative 0 [1 0 0]    positive 2 [0 0 1]\n",
      "neutral 1 [0 1 0]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    neutral 1 [0 1 0]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    negative 0 [1 0 0]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "negative 0 [1 0 0]    neutral 1 [0 1 0]\n",
      "negative 0 [1 0 0]    neutral 1 [0 1 0]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n",
      "positive 2 [0 0 1]    positive 2 [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 檢查polarity跟label有沒有不一樣\n",
    "print('laptop_test', '         ','restaurant_test')\n",
    "for i in range(20):\n",
    "    print(laptop_test.loc[i, 'polarity'], data.loc[5915+i, 'label'], Y_test[i], '  ', restaurant_test.loc[i, 'polarity'], data.loc[6553+i, 'label'], Y_test[638+i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, InputLayer, Bidirectional, concatenate, add, average, Reshape\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把兩邊input merge起來，有加上dropout的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 80, 300)      1967400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 80, 300)      1967400     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 512)          1665024     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 512)          1665024     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          131200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,404,499\n",
      "Trainable params: 7,404,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# first input model 1\n",
    "input_layer_1 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_1 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_1)\n",
    "lstm_hidden_1 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_1) \n",
    "# lstm_hidden_1 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_1) \n",
    "\n",
    "#second input model 2\n",
    "input_layer_2 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_2 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_2)\n",
    "lstm_hidden_2 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_2)\n",
    "# lstm_hidden_2 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_2)\n",
    "\n",
    "#merge input model\n",
    "merge = concatenate([lstm_hidden_1, lstm_hidden_2])\n",
    "# dropout = Dropout(0.2)(merge)\n",
    "hidden_1 = Dense(128, activation='relu')(merge)\n",
    "dropout_1 = Dropout(0.2)(hidden_1)\n",
    "hidden_2 = Dense(64, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(hidden_2)\n",
    "output = Dense(3, activation='softmax')(dropout_2)\n",
    "model = Model(inputs=[input_layer_1, input_layer_2], outputs=output)\n",
    "print(model.summary())\n",
    "adam = Adam(lr=1e-3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1758 samples\n",
      "Epoch 1/30\n",
      "5915/5915 [==============================] - 9s 1ms/sample - loss: 0.8006 - accuracy: 0.6524 - val_loss: 0.6488 - val_accuracy: 0.7173\n",
      "Epoch 2/30\n",
      "5915/5915 [==============================] - 4s 625us/sample - loss: 0.5692 - accuracy: 0.7604 - val_loss: 0.6288 - val_accuracy: 0.7418\n",
      "Epoch 3/30\n",
      "5915/5915 [==============================] - 4s 629us/sample - loss: 0.4217 - accuracy: 0.8348 - val_loss: 0.6922 - val_accuracy: 0.7400\n",
      "Epoch 4/30\n",
      "5915/5915 [==============================] - 6s 977us/sample - loss: 0.3157 - accuracy: 0.8818 - val_loss: 0.7996 - val_accuracy: 0.7457\n",
      "Epoch 5/30\n",
      "5915/5915 [==============================] - 4s 629us/sample - loss: 0.2279 - accuracy: 0.9148 - val_loss: 0.7814 - val_accuracy: 0.7389\n",
      "Epoch 6/30\n",
      "5915/5915 [==============================] - 6s 989us/sample - loss: 0.1776 - accuracy: 0.9332 - val_loss: 0.9535 - val_accuracy: 0.7423\n",
      "Epoch 7/30\n",
      "5915/5915 [==============================] - 4s 632us/sample - loss: 0.1274 - accuracy: 0.9537 - val_loss: 1.1947 - val_accuracy: 0.7412\n",
      "Epoch 8/30\n",
      "5915/5915 [==============================] - 4s 690us/sample - loss: 0.1038 - accuracy: 0.9642 - val_loss: 1.1556 - val_accuracy: 0.7395\n",
      "Epoch 9/30\n",
      "5915/5915 [==============================] - 4s 645us/sample - loss: 0.0879 - accuracy: 0.9699 - val_loss: 1.3773 - val_accuracy: 0.7349\n",
      "Epoch 10/30\n",
      "5824/5915 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9787Restoring model weights from the end of the best epoch.\n",
      "5915/5915 [==============================] - 4s 675us/sample - loss: 0.0667 - accuracy: 0.9790 - val_loss: 1.5426 - val_accuracy: 0.7355\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit([X_left_train, X_right_train],Y_train, batch_size=64,epochs=30,\n",
    "                      validation_data=([X_left_test, X_right_test],Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把兩邊input add or average起來，有加上dropout的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input model 1\n",
    "input_layer_1 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_1 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_1)\n",
    "lstm_hidden_1 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_1) \n",
    "# lstm_hidden_1 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_1) \n",
    "\n",
    "#second input model 2\n",
    "input_layer_2 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_2 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_2)\n",
    "lstm_hidden_2 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_2)\n",
    "# lstm_hidden_2 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_2)\n",
    "\n",
    "#merge input model\n",
    "# added = add([lstm_hidden_1, lstm_hidden_2])\n",
    "averaged = average([lstm_hidden_1, lstm_hidden_2])\n",
    "# dropout = Dropout(0.2)(averaged)\n",
    "hidden_1 = Dense(128, activation='relu')(averaged)\n",
    "dropout_1 = Dropout(0.2)(hidden_1)\n",
    "hidden_2 = Dense(64, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(hidden_2)\n",
    "output = Dense(3, activation='softmax')(dropout_2)\n",
    "model1 = Model(inputs=[input_layer_1, input_layer_2], outputs=output)\n",
    "print(model.summary())\n",
    "adam = Adam(lr=1e-3)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fit = model1.fit([X_left_train, X_right_train],Y_train, batch_size=64,epochs=30,\n",
    "                      validation_data=([X_left_test, X_right_test],Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把兩邊input 丟到另一個LSTM，有加上dropout的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input model 1\n",
    "input_layer_1 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_1 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_1)\n",
    "lstm_hidden_1 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_1) \n",
    "# lstm_hidden_1 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_1) \n",
    "\n",
    "#second input model 2\n",
    "input_layer_2 = Input(shape = (max_seq_length,), dtype='int64')\n",
    "embedding_2 = Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], mask_zero=True, trainable=True)(input_layer_2)\n",
    "lstm_hidden_2 = LSTM(512, return_sequences=False, dropout=0.3)(embedding_2)\n",
    "# lstm_hidden_2 = Bidirectional(LSTM(512, return_sequences=False, dropout=0.4))(embedding_2)\n",
    "\n",
    "#merge input model\n",
    "merge = concatenate([lstm_hidden_1, lstm_hidden_2])\n",
    "merge = Reshape((2, 512))(merge)\n",
    "print(merge.shape)\n",
    "lstm_hidden_3 = LSTM(256, return_sequences=False)(merge)\n",
    "# dropout = Dropout(0.2)(merge)\n",
    "hidden_1 = Dense(128, activation='relu')(lstm_hidden_3)\n",
    "dropout_1 = Dropout(0.2)(hidden_1)\n",
    "hidden_2 = Dense(64, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(hidden_2)\n",
    "output = Dense(3, activation='softmax')(dropout_2)\n",
    "model2 = Model(inputs=[input_layer_1, input_layer_2], outputs=output)\n",
    "print(model.summary())\n",
    "adam = Adam(lr=1e-3)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fit = model2.fit([X_left_train, X_right_train],Y_train, batch_size=64,epochs=30,\n",
    "                      validation_data=([X_left_test, X_right_test],Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7417519908987485\n",
      "[[201  41  82]\n",
      " [ 71 123 171]\n",
      " [ 53  36 980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       324\n",
      "           1       0.61      0.34      0.44       365\n",
      "           2       0.79      0.92      0.85      1069\n",
      "\n",
      "    accuracy                           0.74      1758\n",
      "   macro avg       0.68      0.62      0.64      1758\n",
      "weighted avg       0.72      0.74      0.72      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取所有label中的test label\n",
    "Y_label = data['label'].to_numpy()[5915:]\n",
    "\n",
    "# test data confusion matrix\n",
    "predictions= model.predict([X_left_test, X_right_test]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(Y_label, predictions))\n",
    "print(confusion_matrix(Y_label, predictions))\n",
    "print(classification_report(Y_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6849529780564263\n",
      "[[ 75  29  24]\n",
      " [ 41  68  60]\n",
      " [ 23  24 294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.56       128\n",
      "           1       0.56      0.40      0.47       169\n",
      "           2       0.78      0.86      0.82       341\n",
      "\n",
      "    accuracy                           0.68       638\n",
      "   macro avg       0.63      0.62      0.62       638\n",
      "weighted avg       0.67      0.68      0.67       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取所有label中的laptop test lable\n",
    "laptop_label = data['label'].to_numpy()[5915:6553]\n",
    "\n",
    "# laptop test data confusion matrix\n",
    "predictions= model.predict([X_left_test[:638], X_right_test[:638]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(laptop_label, predictions))\n",
    "print(confusion_matrix(laptop_label, predictions))\n",
    "print(classification_report(laptop_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741071428571429\n",
      "[[126  12  58]\n",
      " [ 30  55 111]\n",
      " [ 30  12 686]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       196\n",
      "           1       0.70      0.28      0.40       196\n",
      "           2       0.80      0.94      0.87       728\n",
      "\n",
      "    accuracy                           0.77      1120\n",
      "   macro avg       0.73      0.62      0.64      1120\n",
      "weighted avg       0.76      0.77      0.75      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取所有label中的restaurant test lable\n",
    "restaurant_label = data['label'].to_numpy()[6553:]\n",
    "\n",
    "# restaurant test data confusion matrix\n",
    "predictions= model.predict([X_left_test[638:], X_right_test[638:]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(restaurant_label, predictions))\n",
    "print(confusion_matrix(restaurant_label, predictions))\n",
    "print(classification_report(restaurant_label, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有label中的test label\n",
    "Y_label = data['label'].to_numpy()[5915:]\n",
    "\n",
    "# test data confusion matrix\n",
    "predictions= model1.predict([X_left_test, X_right_test]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(Y_label, predictions))\n",
    "print(confusion_matrix(Y_label, predictions))\n",
    "print(classification_report(Y_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有label中的laptop test lable\n",
    "laptop_label = data['label'].to_numpy()[5915:6553]\n",
    "\n",
    "# laptop test data confusion matrix\n",
    "predictions= model1.predict([X_left_test[:638], X_right_test[:638]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(laptop_label, predictions))\n",
    "print(confusion_matrix(laptop_label, predictions))\n",
    "print(classification_report(laptop_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有label中的restaurant test lable\n",
    "restaurant_label = data['label'].to_numpy()[6553:]\n",
    "\n",
    "# restaurant test data confusion matrix\n",
    "predictions= model1.predict([X_left_test[638:], X_right_test[638:]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(restaurant_label, predictions))\n",
    "print(confusion_matrix(restaurant_label, predictions))\n",
    "print(classification_report(restaurant_label, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有label中的test label\n",
    "Y_label = data['label'].to_numpy()[5915:]\n",
    "\n",
    "# test data confusion matrix\n",
    "predictions= model2.predict([X_left_test, X_right_test]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(Y_label, predictions))\n",
    "print(confusion_matrix(Y_label, predictions))\n",
    "print(classification_report(Y_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有label中的laptop test lable\n",
    "laptop_label = data['label'].to_numpy()[5915:6553]\n",
    "\n",
    "# laptop test data confusion matrix\n",
    "predictions= model2.predict([X_left_test[:638], X_right_test[:638]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(laptop_label, predictions))\n",
    "print(confusion_matrix(laptop_label, predictions))\n",
    "print(classification_report(laptop_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有label中的restaurant test lable\n",
    "restaurant_label = data['label'].to_numpy()[6553:]\n",
    "\n",
    "# restaurant test data confusion matrix\n",
    "predictions= model2.predict([X_left_test[638:], X_right_test[638:]]) # 輸出的是n*5的編碼值array\n",
    "predictions = np.argmax(predictions, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "predictions\n",
    "print(accuracy_score(restaurant_label, predictions))\n",
    "print(confusion_matrix(restaurant_label, predictions))\n",
    "print(classification_report(restaurant_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
