{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 單純用BERT去預測一個句子的label，在句子的sep token後面再加上aspect term token (CLS+text+SEP+aspect)，測試unique input (可以看做那句子是只屬於對應aspect)對aspect term polarity準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對處理好的laptop、restaurant的train、test資料作前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料數: 5915\n",
      "筆電測試資料數: 638\n",
      "餐廳測試資料數: 1120\n",
      "測試資料數: 1758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>appetizers</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>dim sum</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>foods</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>table</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>pot of boiling water</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>meats</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>vegetables</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>rice</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>glass noodles</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text                aspect  \\\n",
       "5905  From the appetizers we ate, the dim sum and ot...            appetizers   \n",
       "5906  From the appetizers we ate, the dim sum and ot...               dim sum   \n",
       "5907  From the appetizers we ate, the dim sum and ot...                 foods   \n",
       "5908  From the appetizers we ate, the dim sum and ot...                  food   \n",
       "5909  Each table has a pot of boiling water sunken i...                 table   \n",
       "5910  Each table has a pot of boiling water sunken i...  pot of boiling water   \n",
       "5911  Each table has a pot of boiling water sunken i...                 meats   \n",
       "5912  Each table has a pot of boiling water sunken i...            vegetables   \n",
       "5913  Each table has a pot of boiling water sunken i...                  rice   \n",
       "5914  Each table has a pot of boiling water sunken i...         glass noodles   \n",
       "\n",
       "      polarity  \n",
       "5905  positive  \n",
       "5906  positive  \n",
       "5907  positive  \n",
       "5908  positive  \n",
       "5909   neutral  \n",
       "5910   neutral  \n",
       "5911   neutral  \n",
       "5912   neutral  \n",
       "5913   neutral  \n",
       "5914   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_train = pd.read_csv('dataset/laptop_train_processed.csv', encoding='utf-8')\n",
    "restaurant_train = pd.read_csv('dataset/restaurant_train_processed.csv', encoding='utf-8')\n",
    "laptop_test = pd.read_csv('dataset/laptop_test_processed.csv', encoding='utf-8')\n",
    "restaurant_test = pd.read_csv('dataset/restaurant_test_processed.csv', encoding='utf-8')\n",
    "\n",
    "# 把train的資料串在一起且多加一個aspect\n",
    "train_data = laptop_train.append(restaurant_train)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# 把test的資料串在一起且多加一個aspect\n",
    "test_data = laptop_test.append(restaurant_test)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "print('訓練資料數:', len(train_data))\n",
    "print('筆電測試資料數:', len(laptop_test))\n",
    "print('餐廳測試資料數:', len(restaurant_test))\n",
    "print('測試資料數:', len(test_data))\n",
    "train_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech support would not fix the problem unless ...</td>\n",
       "      <td>tech support</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set up was easy.</td>\n",
       "      <td>Set up</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>Windows 8</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>touchscreen functions</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>internal speakers</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>price tag</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>click pads</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No installation disk (DVD) is included.</td>\n",
       "      <td>installation disk (DVD)</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's fast, light, and simple to use.</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   aspect  \\\n",
       "0  Boot time is super fast, around anywhere from ...                Boot time   \n",
       "1  tech support would not fix the problem unless ...             tech support   \n",
       "2                                   Set up was easy.                   Set up   \n",
       "3  Did not enjoy the new Windows 8 and touchscree...                Windows 8   \n",
       "4  Did not enjoy the new Windows 8 and touchscree...    touchscreen functions   \n",
       "5  Other than not being a fan of click pads (indu...        internal speakers   \n",
       "6  Other than not being a fan of click pads (indu...                price tag   \n",
       "7  Other than not being a fan of click pads (indu...               click pads   \n",
       "8            No installation disk (DVD) is included.  installation disk (DVD)   \n",
       "9               It's fast, light, and simple to use.                      use   \n",
       "\n",
       "   polarity  label  \n",
       "0  positive      2  \n",
       "1  negative      0  \n",
       "2  positive      2  \n",
       "3  negative      0  \n",
       "4  negative      0  \n",
       "5  negative      0  \n",
       "6  positive      2  \n",
       "7  negative      0  \n",
       "8   neutral      1  \n",
       "9  positive      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把polarity變成數字的label，positive是2，neutral是1，negative是0\n",
    "train_data.loc[train_data['polarity']=='positive', 'label'] = 2\n",
    "train_data.loc[train_data['polarity']=='negative', 'label'] = 0\n",
    "train_data.loc[train_data['polarity']=='neutral', 'label'] = 1\n",
    "train_data['label'] = train_data['label'].astype(int)\n",
    "\n",
    "test_data.loc[test_data['polarity']=='positive', 'label'] = 2\n",
    "test_data.loc[test_data['polarity']=='negative', 'label'] = 0\n",
    "test_data.loc[test_data['polarity']=='neutral', 'label'] = 1\n",
    "test_data['label'] = test_data['label'].astype(int)\n",
    "\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel, TFBertForSequenceClassification, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer, to convert our text into tokens that correspond to BERT’s vocabulary.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7814, 2744, 19204]\n",
      "[7814, 2744]\n",
      "[101, 7814, 2744, 19204, 102]\n",
      "[101, 7814, 2744, 19204, 102, 7814, 2744]\n"
     ]
    }
   ],
   "source": [
    "# 把aspect term token串在sep後面的練習\n",
    "text = 'aspect term token'\n",
    "aspect = 'aspect term'\n",
    "text_tok = tokenizer.tokenize(text) # 把文字變成token\n",
    "aspect_tok = tokenizer.tokenize(aspect)\n",
    "text_id = tokenizer.convert_tokens_to_ids(text_tok) # 把token變成Id\n",
    "aspect_id = tokenizer.convert_tokens_to_ids(aspect_tok)\n",
    "print(text_id)\n",
    "print(aspect_id)\n",
    "text_cls_sep = tokenizer.build_inputs_with_special_tokens(text_id) # 加入CLS、SEP token id\n",
    "print(text_cls_sep)\n",
    "text_sep_aspect = text_cls_sep + aspect_id\n",
    "print(text_sep_aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 找出單句最多token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出最多text add aspect中最多是幾個token，不包含CLS跟SEP\n",
    "def find_max_token(pd):\n",
    "    max_token = 0\n",
    "    for i in range(len(pd)):\n",
    "        text = pd.loc[i, 'text']\n",
    "        aspect = pd.loc[i, 'aspect']\n",
    "        text_aspect = text + aspect\n",
    "        tokens_len = len(tokenizer.tokenize(text_aspect))\n",
    "        if tokens_len>max_token:\n",
    "            max_token = tokens_len\n",
    "    return max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集token最多是: 91\n",
      "測試資料集token最多是: 99\n"
     ]
    }
   ],
   "source": [
    "# 找出text add aspect中token最多的是幾個token，不包含CLS跟SEP\n",
    "train_max_token = find_max_token(train_data)\n",
    "test_max_token = find_max_token(test_data)\n",
    "print('訓練資料集token最多是:', train_max_token)\n",
    "print('測試資料集token最多是:', test_max_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正式把資料轉換成token(padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把句子轉變成token(CLS+text+SEP+asepct)+(padding)的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把維度固定在128維\n",
    "input_dim = 128\n",
    "def input_ids_all(pd):\n",
    "    pd['input_ids'] = 'N/A'\n",
    "    for i in range(len(pd)):\n",
    "        text = pd.loc[i, 'text']\n",
    "        aspect = pd.loc[i, 'aspect']\n",
    "        text_tokens = tokenizer.tokenize(text) # 把text轉成token\n",
    "        aspect_tokens = tokenizer.tokenize(aspect) # 把aspect轉成token\n",
    "        \n",
    "        text_input_ids = tokenizer.convert_tokens_to_ids(text_tokens) # 把text token轉成text token id\n",
    "        aspect_input_ids = tokenizer.convert_tokens_to_ids(aspect_tokens) # 把aspect token轉成aspect token id\n",
    "        \n",
    "        text_input_ids_cls = tokenizer.build_inputs_with_special_tokens(text_input_ids) # aspect token id加上CLS、SEP token id\n",
    "        input_ids = text_input_ids_cls + aspect_input_ids # 把aspect token id接在text token id 後面 (CLS+text+SEP+aspect)\n",
    "        input_ids = np.array(input_ids)\n",
    "        \n",
    "        if len(input_ids) < input_dim:\n",
    "            n = input_dim - len(input_ids)\n",
    "            input_ids = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0  補長度到512\n",
    "        \n",
    "        pd['input_ids'][i] = input_ids\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/bertenv2/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 將text轉成token，後面加上aspect token存進dataframe\n",
    "train_data = input_ids_all(train_data)\n",
    "test_data = input_ids_all(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把句子轉變成token(CLS+text+SEP+asepct)+(padding)的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把維度固定在128維\n",
    "input_dim = 128\n",
    "def input_ids_all_2(text, aspect):\n",
    "    text_tokens = tokenizer.tokenize(text) # 把text轉成token\n",
    "    aspect_tokens = tokenizer.tokenize(aspect) # 把aspect轉成token\n",
    "        \n",
    "    text_input_ids = tokenizer.convert_tokens_to_ids(text_tokens) # 把text token轉成text token id\n",
    "    aspect_input_ids = tokenizer.convert_tokens_to_ids(aspect_tokens) # 把aspect token轉成aspect token id\n",
    "        \n",
    "    text_input_ids_cls = tokenizer.build_inputs_with_special_tokens(text_input_ids) # aspect token id加上CLS、SEP token id\n",
    "    input_ids = text_input_ids_cls + aspect_input_ids # 把aspect token id接在text token id 後面 (CLS+text+SEP+aspect)\n",
    "    input_ids = np.array(input_ids)\n",
    "        \n",
    "    if len(input_ids) < input_dim:\n",
    "        n = input_dim - len(input_ids)\n",
    "        input_ids = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0  補長度到512\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['input_ids_2'] = train_data.apply(lambda column: input_ids_all_2(column['text'], column['aspect']), axis=1)\n",
    "test_data['input_ids_2'] = test_data.apply(lambda column: input_ids_all_2(column['text'], column['aspect']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The music is the best among all the Indian restaurants I have visited.\n",
      "music\n",
      "[ 101 1996 2189 2003 1996 2190 2426 2035 1996 2796 7884 1045 2031 4716\n",
      " 1012  102 2189    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[ 101 1996 2189 2003 1996 2190 2426 2035 1996 2796 7884 1045 2031 4716\n",
      " 1012  102 2189    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "n = 4500\n",
    "print(train_data.loc[n, 'text'])\n",
    "print(train_data.loc[n, 'aspect'])\n",
    "print(train_data.loc[n, 'input_ids'])\n",
    "print(train_data.loc[n, 'input_ids_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additionally, there is barely a ventilation system in the computer, and even the simple activity of watching videos let alone playing steam games causes the laptop to get very very hot, and in fact impossible to keep on lap.\n",
      "playing steam games\n",
      "[  101  5678  1010  2045  2003  4510  1037 19536  2291  1999  1996  3274\n",
      "  1010  1998  2130  1996  3722  4023  1997  3666  6876  2292  2894  2652\n",
      "  5492  2399  5320  1996 12191  2000  2131  2200  2200  2980  1010  1998\n",
      "  1999  2755  5263  2000  2562  2006  5001  1012   102  2652  5492  2399\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[  101  5678  1010  2045  2003  4510  1037 19536  2291  1999  1996  3274\n",
      "  1010  1998  2130  1996  3722  4023  1997  3666  6876  2292  2894  2652\n",
      "  5492  2399  5320  1996 12191  2000  2131  2200  2200  2980  1010  1998\n",
      "  1999  2755  5263  2000  2562  2006  5001  1012   102  2652  5492  2399\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "print(test_data.loc[n, 'text'])\n",
    "print(test_data.loc[n, 'aspect'])\n",
    "print(test_data.loc[n, 'input_ids'])\n",
    "print(test_data.loc[n, 'input_ids_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 101, 1045, 3715, ...,    0,    0,    0],\n",
       "       [ 101, 1045, 3715, ...,    0,    0,    0],\n",
       "       [ 101, 1996, 6627, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 2169, 2795, ...,    0,    0,    0],\n",
       "       [ 101, 2169, 2795, ...,    0,    0,    0],\n",
       "       [ 101, 2169, 2795, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把train data的input_ids提出存進list\n",
    "train_input_ids = list()\n",
    "for i in range(len(train_data)):\n",
    "    np_id = train_data.loc[i, 'input_ids']\n",
    "    train_input_ids.append(np_id)\n",
    "train_input_ids = np.array(train_input_ids)\n",
    "print(train_input_ids.shape)\n",
    "train_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1758, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  101,  9573,  2051, ...,     0,     0,     0],\n",
       "       [  101,  6627,  2490, ...,     0,     0,     0],\n",
       "       [  101,  2275,  2039, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0],\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0],\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data的input_ids提出存進list\n",
    "test_input_ids = list()\n",
    "for i in range(len(test_data)):\n",
    "    np_id = test_data.loc[i, 'input_ids']\n",
    "    test_input_ids.append(np_id)\n",
    "test_input_ids = np.array(test_input_ids)\n",
    "print(test_input_ids.shape)\n",
    "test_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把train data label變成numpy\n",
    "train_label = train_data['label'].to_numpy()\n",
    "print(len(train_label))\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把test data label變成numpy\n",
    "test_label = test_data['label'].to_numpy()\n",
    "print(len(test_label))\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "neutral 1 1\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n"
     ]
    }
   ],
   "source": [
    "# 檢查polarity跟label有沒有不一樣\n",
    "print('test_data')\n",
    "for i in range(15):\n",
    "    print(test_data.loc[i, 'polarity'], test_data.loc[i, 'label'], test_label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  2307      \n",
      "=================================================================\n",
      "Total params: 109,484,547\n",
      "Trainable params: 109,484,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \n",
    "# num_labels=3 分3類\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1758 samples\n",
      "Epoch 1/5\n",
      "5915/5915 [==============================] - 134s 23ms/sample - loss: 0.8494 - accuracy: 0.6228 - val_loss: 0.5529 - val_accuracy: 0.7770\n",
      "Epoch 2/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.5502 - accuracy: 0.7838 - val_loss: 0.5552 - val_accuracy: 0.7907\n",
      "Epoch 3/5\n",
      "5915/5915 [==============================] - 125s 21ms/sample - loss: 0.3626 - accuracy: 0.8578 - val_loss: 0.5451 - val_accuracy: 0.7947\n",
      "Epoch 4/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.2387 - accuracy: 0.9172 - val_loss: 0.6034 - val_accuracy: 0.8163\n",
      "Epoch 5/5\n",
      "5915/5915 [==============================] - 124s 21ms/sample - loss: 0.1704 - accuracy: 0.9418 - val_loss: 0.5675 - val_accuracy: 0.8288\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_input_ids, train_label, \n",
    "                      batch_size=4, epochs=5, \n",
    "                      validation_data=(test_input_ids, test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8287827076222981\n",
      "[[ 234   38   52]\n",
      " [  47  208  110]\n",
      " [  20   34 1015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75       324\n",
      "           1       0.74      0.57      0.64       365\n",
      "           2       0.86      0.95      0.90      1069\n",
      "\n",
      "    accuracy                           0.83      1758\n",
      "   macro avg       0.79      0.75      0.77      1758\n",
      "weighted avg       0.82      0.83      0.82      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test data confusion\n",
    "predictions_test= model.predict(test_input_ids) # 輸出的是n*5的編碼值array\n",
    "predictions_test = np.argmax(predictions_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(test_label, predictions_test))\n",
    "print(confusion_matrix(test_label, predictions_test))\n",
    "print(classification_report(test_label, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786833855799373\n",
      "[[ 98  13  17]\n",
      " [ 35  90  44]\n",
      " [ 14  13 314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.71       128\n",
      "           1       0.78      0.53      0.63       169\n",
      "           2       0.84      0.92      0.88       341\n",
      "\n",
      "    accuracy                           0.79       638\n",
      "   macro avg       0.76      0.74      0.74       638\n",
      "weighted avg       0.79      0.79      0.78       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laptop_test confusion\n",
    "laptop_test_input_ids = test_input_ids[:638]\n",
    "laptop_test_label = test_label[:638]\n",
    "predictions_lap_test = model.predict(laptop_test_input_ids)\n",
    "predictions_lap_test = np.argmax(predictions_lap_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(laptop_test_label, predictions_lap_test))\n",
    "print(confusion_matrix(laptop_test_label, predictions_lap_test))\n",
    "print(classification_report(laptop_test_label, predictions_lap_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526785714285714\n",
      "[[136  25  35]\n",
      " [ 12 118  66]\n",
      " [  6  21 701]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78       196\n",
      "           1       0.72      0.60      0.66       196\n",
      "           2       0.87      0.96      0.92       728\n",
      "\n",
      "    accuracy                           0.85      1120\n",
      "   macro avg       0.83      0.75      0.78      1120\n",
      "weighted avg       0.85      0.85      0.85      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laptop_test confusion\n",
    "restaurant_test_input_ids = test_input_ids[638:]\n",
    "restaurant_test_label = test_label[638:]\n",
    "predictions_res_test = model.predict(restaurant_test_input_ids)\n",
    "predictions_res_test = np.argmax(predictions_res_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(restaurant_test_label, predictions_res_test))\n",
    "print(confusion_matrix(restaurant_test_label, predictions_res_test))\n",
    "print(classification_report(restaurant_test_label, predictions_res_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
