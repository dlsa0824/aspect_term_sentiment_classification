{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 單純用BERT去預測一個句子的label，在句子的sep token後面再加上aspect term token (CLS+text+SEP+aspect+SEP)，測試unique input (可以看做那句子是只屬於對應aspect)對aspect term polarity準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 對處理好的laptop、restaurant的train、test資料作前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料數: 5915\n",
      "筆電測試資料數: 638\n",
      "餐廳測試資料數: 1120\n",
      "測試資料數: 1758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>appetizers</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>dim sum</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>foods</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>table</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>pot of boiling water</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>meats</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>vegetables</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>rice</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>glass noodles</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text                aspect  \\\n",
       "5905  From the appetizers we ate, the dim sum and ot...            appetizers   \n",
       "5906  From the appetizers we ate, the dim sum and ot...               dim sum   \n",
       "5907  From the appetizers we ate, the dim sum and ot...                 foods   \n",
       "5908  From the appetizers we ate, the dim sum and ot...                  food   \n",
       "5909  Each table has a pot of boiling water sunken i...                 table   \n",
       "5910  Each table has a pot of boiling water sunken i...  pot of boiling water   \n",
       "5911  Each table has a pot of boiling water sunken i...                 meats   \n",
       "5912  Each table has a pot of boiling water sunken i...            vegetables   \n",
       "5913  Each table has a pot of boiling water sunken i...                  rice   \n",
       "5914  Each table has a pot of boiling water sunken i...         glass noodles   \n",
       "\n",
       "      polarity  \n",
       "5905  positive  \n",
       "5906  positive  \n",
       "5907  positive  \n",
       "5908  positive  \n",
       "5909   neutral  \n",
       "5910   neutral  \n",
       "5911   neutral  \n",
       "5912   neutral  \n",
       "5913   neutral  \n",
       "5914   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_train = pd.read_csv('dataset/laptop_train_processed.csv', encoding='utf-8')\n",
    "restaurant_train = pd.read_csv('dataset/restaurant_train_processed.csv', encoding='utf-8')\n",
    "laptop_test = pd.read_csv('dataset/laptop_test_processed.csv', encoding='utf-8')\n",
    "restaurant_test = pd.read_csv('dataset/restaurant_test_processed.csv', encoding='utf-8')\n",
    "\n",
    "# 把train的資料串在一起且多加一個aspect\n",
    "train_data = laptop_train.append(restaurant_train)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# 把test的資料串在一起且多加一個aspect\n",
    "test_data = laptop_test.append(restaurant_test)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "print('訓練資料數:', len(train_data))\n",
    "print('筆電測試資料數:', len(laptop_test))\n",
    "print('餐廳測試資料數:', len(restaurant_test))\n",
    "print('測試資料數:', len(test_data))\n",
    "train_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boot time is super fast, around anywhere from ...</td>\n",
       "      <td>Boot time</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech support would not fix the problem unless ...</td>\n",
       "      <td>tech support</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set up was easy.</td>\n",
       "      <td>Set up</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>Windows 8</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did not enjoy the new Windows 8 and touchscree...</td>\n",
       "      <td>touchscreen functions</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>internal speakers</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>price tag</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other than not being a fan of click pads (indu...</td>\n",
       "      <td>click pads</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No installation disk (DVD) is included.</td>\n",
       "      <td>installation disk (DVD)</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's fast, light, and simple to use.</td>\n",
       "      <td>use</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   aspect  \\\n",
       "0  Boot time is super fast, around anywhere from ...                Boot time   \n",
       "1  tech support would not fix the problem unless ...             tech support   \n",
       "2                                   Set up was easy.                   Set up   \n",
       "3  Did not enjoy the new Windows 8 and touchscree...                Windows 8   \n",
       "4  Did not enjoy the new Windows 8 and touchscree...    touchscreen functions   \n",
       "5  Other than not being a fan of click pads (indu...        internal speakers   \n",
       "6  Other than not being a fan of click pads (indu...                price tag   \n",
       "7  Other than not being a fan of click pads (indu...               click pads   \n",
       "8            No installation disk (DVD) is included.  installation disk (DVD)   \n",
       "9               It's fast, light, and simple to use.                      use   \n",
       "\n",
       "   polarity  label  \n",
       "0  positive      2  \n",
       "1  negative      0  \n",
       "2  positive      2  \n",
       "3  negative      0  \n",
       "4  negative      0  \n",
       "5  negative      0  \n",
       "6  positive      2  \n",
       "7  negative      0  \n",
       "8   neutral      1  \n",
       "9  positive      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把polarity變成數字的label，positive是2，neutral是1，negative是0\n",
    "train_data.loc[train_data['polarity']=='positive', 'label'] = 2\n",
    "train_data.loc[train_data['polarity']=='negative', 'label'] = 0\n",
    "train_data.loc[train_data['polarity']=='neutral', 'label'] = 1\n",
    "train_data['label'] = train_data['label'].astype(int)\n",
    "\n",
    "test_data.loc[test_data['polarity']=='positive', 'label'] = 2\n",
    "test_data.loc[test_data['polarity']=='negative', 'label'] = 0\n",
    "test_data.loc[test_data['polarity']=='neutral', 'label'] = 1\n",
    "test_data['label'] = test_data['label'].astype(int)\n",
    "\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel, TFBertForSequenceClassification, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer, to convert our text into tokens that correspond to BERT’s vocabulary.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7814, 2744, 19204]\n",
      "[7814, 2744]\n",
      "[101, 7814, 2744, 19204, 102]\n",
      "[101, 7814, 2744, 19204, 102, 7814, 2744]\n"
     ]
    }
   ],
   "source": [
    "# 把aspect term token串在sep後面的練習\n",
    "text = 'aspect term token'\n",
    "aspect = 'aspect term'\n",
    "text_tok = tokenizer.tokenize(text) # 把文字變成token\n",
    "aspect_tok = tokenizer.tokenize(aspect)\n",
    "text_id = tokenizer.convert_tokens_to_ids(text_tok) # 把token變成Id\n",
    "aspect_id = tokenizer.convert_tokens_to_ids(aspect_tok)\n",
    "print(text_id)\n",
    "print(aspect_id)\n",
    "text_cls_sep = tokenizer.build_inputs_with_special_tokens(text_id) # 加入CLS、SEP token id\n",
    "print(text_cls_sep)\n",
    "text_sep_aspect = text_cls_sep + aspect_id\n",
    "print(text_sep_aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 找出單句最多token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出最多text add aspect中最多是幾個token，不包含CLS跟SEP\n",
    "def find_max_token(pd):\n",
    "    max_token = 0\n",
    "    for i in range(len(pd)):\n",
    "        text = pd.loc[i, 'text']\n",
    "        aspect = pd.loc[i, 'aspect']\n",
    "        text_aspect = text + aspect\n",
    "        tokens_len = len(tokenizer.tokenize(text_aspect))\n",
    "        if tokens_len>max_token:\n",
    "            max_token = tokens_len\n",
    "    return max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集token最多是: 91\n",
      "測試資料集token最多是: 99\n"
     ]
    }
   ],
   "source": [
    "# 找出text add aspect中token最多的是幾個token，不包含CLS跟SEP\n",
    "train_max_token = find_max_token(train_data)\n",
    "test_max_token = find_max_token(test_data)\n",
    "print('訓練資料集token最多是:', train_max_token)\n",
    "print('測試資料集token最多是:', test_max_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正式把資料轉換成token(padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把句子轉變成token(CLS+text+SEP+asepct+SEP)+(padding)的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把維度固定在128維\n",
    "input_dim = 128\n",
    "def input_ids_all(pd):\n",
    "    pd['input_ids'] = 'N/A'\n",
    "    for i in range(len(pd)):\n",
    "        text = pd.loc[i, 'text']\n",
    "        aspect = pd.loc[i, 'aspect']\n",
    "        text_tokens = tokenizer.tokenize(text) # 把text轉成token\n",
    "        aspect_tokens = tokenizer.tokenize(aspect) # 把aspect轉成token\n",
    "        \n",
    "        text_input_ids = tokenizer.convert_tokens_to_ids(text_tokens) # 把text token轉成text token id\n",
    "        aspect_input_ids = tokenizer.convert_tokens_to_ids(aspect_tokens) # 把aspect token轉成aspect token id\n",
    "        \n",
    "        text_input_ids_cls = tokenizer.build_inputs_with_special_tokens(text_input_ids) # aspect token id加上CLS、SEP token id\n",
    "        input_ids = text_input_ids_cls + aspect_input_ids # 把aspect token id接在text token id 後面 (CLS+text+SEP+aspect)\n",
    "        input_ids.append(102)\n",
    "        input_ids = np.array(input_ids)\n",
    "        \n",
    "        if len(input_ids) < input_dim:\n",
    "            n = input_dim - len(input_ids)\n",
    "            input_ids = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0  補長度到512\n",
    "        \n",
    "        pd['input_ids'][i] = input_ids\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/bertenv/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 將text轉成token，後面加上aspect token存進dataframe\n",
    "train_data = input_ids_all(train_data)\n",
    "test_data = input_ids_all(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把句子轉變成token(CLS+text+SEP+asepct)+(padding)的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把維度固定在128維\n",
    "input_dim = 128\n",
    "def input_ids_all_2(text, aspect):\n",
    "    text_tokens = tokenizer.tokenize(text) # 把text轉成token\n",
    "    aspect_tokens = tokenizer.tokenize(aspect) # 把aspect轉成token\n",
    "        \n",
    "    text_input_ids = tokenizer.convert_tokens_to_ids(text_tokens) # 把text token轉成text token id\n",
    "    aspect_input_ids = tokenizer.convert_tokens_to_ids(aspect_tokens) # 把aspect token轉成aspect token id\n",
    "        \n",
    "    text_input_ids_cls = tokenizer.build_inputs_with_special_tokens(text_input_ids) # aspect token id加上CLS、SEP token id\n",
    "    input_ids = text_input_ids_cls + aspect_input_ids # 把aspect token id接在text token id 後面 (CLS+text+SEP+aspect)\n",
    "    input_ids.append(102)\n",
    "    input_ids = np.array(input_ids)\n",
    "        \n",
    "    if len(input_ids) < input_dim:\n",
    "        n = input_dim - len(input_ids)\n",
    "        input_ids = np.pad(input_ids, (0, n), mode ='constant', constant_values=(0)) # array右邊append n 個 0  補長度到512\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['input_ids_2'] = train_data.apply(lambda column: input_ids_all_2(column['text'], column['aspect']), axis=1)\n",
    "test_data['input_ids_2'] = test_data.apply(lambda column: input_ids_all_2(column['text'], column['aspect']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The place is sleek, modern and playfull and i will return again frequently.\n",
      "place\n",
      "[  101  1996  2173  2003 21185  1010  2715  1998 18378  2140  1998  1045\n",
      "  2097  2709  2153  4703  1012   102  2173   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[  101  1996  2173  2003 21185  1010  2715  1998 18378  2140  1998  1045\n",
      "  2097  2709  2153  4703  1012   102  2173   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "n = 5111\n",
    "print(train_data.loc[n, 'text'])\n",
    "print(train_data.loc[n, 'aspect'])\n",
    "print(train_data.loc[n, 'input_ids'])\n",
    "print(train_data.loc[n, 'input_ids_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But I wanted the Pro for the CD/DVD player.\n",
      "CD/DVD player\n",
      "[ 101 2021 1045 2359 1996 4013 2005 1996 3729 1013 4966 2447 1012  102\n",
      " 3729 1013 4966 2447  102    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[ 101 2021 1045 2359 1996 4013 2005 1996 3729 1013 4966 2447 1012  102\n",
      " 3729 1013 4966 2447  102    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "n = 509\n",
    "print(test_data.loc[n, 'text'])\n",
    "print(test_data.loc[n, 'aspect'])\n",
    "print(test_data.loc[n, 'input_ids'])\n",
    "print(test_data.loc[n, 'input_ids_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5915, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 101, 1045, 3715, ...,    0,    0,    0],\n",
       "       [ 101, 1045, 3715, ...,    0,    0,    0],\n",
       "       [ 101, 1996, 6627, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 2169, 2795, ...,    0,    0,    0],\n",
       "       [ 101, 2169, 2795, ...,    0,    0,    0],\n",
       "       [ 101, 2169, 2795, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把train data的input_ids提出存進list\n",
    "train_input_ids = list()\n",
    "for i in range(len(train_data)):\n",
    "    np_id = train_data.loc[i, 'input_ids']\n",
    "    train_input_ids.append(np_id)\n",
    "train_input_ids = np.array(train_input_ids)\n",
    "print(train_input_ids.shape)\n",
    "train_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1758, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  101,  9573,  2051, ...,     0,     0,     0],\n",
       "       [  101,  6627,  2490, ...,     0,     0,     0],\n",
       "       [  101,  2275,  2039, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0],\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0],\n",
       "       [  101, 24519, 10439, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data的input_ids提出存進list\n",
    "test_input_ids = list()\n",
    "for i in range(len(test_data)):\n",
    "    np_id = test_data.loc[i, 'input_ids']\n",
    "    test_input_ids.append(np_id)\n",
    "test_input_ids = np.array(test_input_ids)\n",
    "print(test_input_ids.shape)\n",
    "test_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把train data label變成numpy\n",
    "train_label = train_data['label'].to_numpy()\n",
    "print(len(train_label))\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把test data label變成numpy\n",
    "test_label = test_data['label'].to_numpy()\n",
    "print(len(test_label))\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "negative 0 0\n",
      "positive 2 2\n",
      "negative 0 0\n",
      "neutral 1 1\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n",
      "positive 2 2\n"
     ]
    }
   ],
   "source": [
    "# 檢查polarity跟label有沒有不一樣\n",
    "print('test_data')\n",
    "for i in range(15):\n",
    "    print(test_data.loc[i, 'polarity'], test_data.loc[i, 'label'], test_label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  2307      \n",
      "=================================================================\n",
      "Total params: 109,484,547\n",
      "Trainable params: 109,484,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \n",
    "# num_labels=3 分3類\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1758 samples\n",
      "Epoch 1/4\n",
      "5915/5915 [==============================] - 144s 24ms/sample - loss: 0.6917 - accuracy: 0.7187 - val_loss: 0.5860 - val_accuracy: 0.7497\n",
      "Epoch 2/4\n",
      "5915/5915 [==============================] - 130s 22ms/sample - loss: 0.4406 - accuracy: 0.8326 - val_loss: 0.4966 - val_accuracy: 0.8100\n",
      "Epoch 3/4\n",
      "5915/5915 [==============================] - 130s 22ms/sample - loss: 0.2955 - accuracy: 0.8898 - val_loss: 0.4807 - val_accuracy: 0.8197\n",
      "Epoch 4/4\n",
      "5915/5915 [==============================] - 130s 22ms/sample - loss: 0.1943 - accuracy: 0.9349 - val_loss: 0.5324 - val_accuracy: 0.8203\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_input_ids, train_label, \n",
    "                      batch_size=4, epochs=4, \n",
    "                      validation_data=(test_input_ids, test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820250284414107\n",
      "[[285  23  16]\n",
      " [ 91 191  83]\n",
      " [ 68  35 966]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74       324\n",
      "           1       0.77      0.52      0.62       365\n",
      "           2       0.91      0.90      0.91      1069\n",
      "\n",
      "    accuracy                           0.82      1758\n",
      "   macro avg       0.77      0.77      0.76      1758\n",
      "weighted avg       0.83      0.82      0.82      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test data confusion\n",
    "predictions_test= model.predict(test_input_ids) # 輸出的是n*5的編碼值array\n",
    "predictions_test = np.argmax(predictions_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(test_label, predictions_test))\n",
    "print(confusion_matrix(test_label, predictions_test))\n",
    "print(classification_report(test_label, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7617554858934169\n",
      "[[118   6   4]\n",
      " [ 63  76  30]\n",
      " [ 31  18 292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.92      0.69       128\n",
      "           1       0.76      0.45      0.57       169\n",
      "           2       0.90      0.86      0.88       341\n",
      "\n",
      "    accuracy                           0.76       638\n",
      "   macro avg       0.74      0.74      0.71       638\n",
      "weighted avg       0.79      0.76      0.76       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laptop_test confusion\n",
    "laptop_test_input_ids = test_input_ids[:638]\n",
    "laptop_test_label = test_label[:638]\n",
    "predictions_lap_test = model.predict(laptop_test_input_ids)\n",
    "predictions_lap_test = np.argmax(predictions_lap_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(laptop_test_label, predictions_lap_test))\n",
    "print(confusion_matrix(laptop_test_label, predictions_lap_test))\n",
    "print(classification_report(laptop_test_label, predictions_lap_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8535714285714285\n",
      "[[167  17  12]\n",
      " [ 28 115  53]\n",
      " [ 37  17 674]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78       196\n",
      "           1       0.77      0.59      0.67       196\n",
      "           2       0.91      0.93      0.92       728\n",
      "\n",
      "    accuracy                           0.85      1120\n",
      "   macro avg       0.80      0.79      0.79      1120\n",
      "weighted avg       0.85      0.85      0.85      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laptop_test confusion\n",
    "restaurant_test_input_ids = test_input_ids[638:]\n",
    "restaurant_test_label = test_label[638:]\n",
    "predictions_res_test = model.predict(restaurant_test_input_ids)\n",
    "predictions_res_test = np.argmax(predictions_res_test, axis=1) # axis = 1是取行的最大值的索引，0是列的最大值的索引\n",
    "print(accuracy_score(restaurant_test_label, predictions_res_test))\n",
    "print(confusion_matrix(restaurant_test_label, predictions_res_test))\n",
    "print(classification_report(restaurant_test_label, predictions_res_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
